{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zriTdjauH8iQ"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQiRPWWHlSgv"
      },
      "source": [
        "### Using pre-trained transformers\n",
        "_for fun and profit_\n",
        "\n",
        "There are many toolkits that let you access pre-trained transformer models, but the most powerful and convenient by far is [`huggingface/transformers`](https://github.com/huggingface/transformers). In this week's practice, you'll learn how to download, apply and modify pre-trained transformers for a range of tasks. Buckle up, we're going in!\n",
        "\n",
        "\n",
        "__Pipelines:__ if all you want is to apply a pre-trained model, you can do that in one line of code using pipeline. Huggingface/transformers has a selection of pre-configured pipelines for masked language modelling, sentiment classification, question aswering, etc. ([see full list here](https://huggingface.co/transformers/main_classes/pipelines.html))\n",
        "\n",
        "A typical pipeline includes:\n",
        "* pre-processing, e.g. tokenization, subword segmentation\n",
        "* a backbone model, e.g. bert finetuned for classification\n",
        "* output post-processing\n",
        "\n",
        "Let's see it in action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rP1KFtvLlJHR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9998860359191895}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.9996429681777954}]\n",
            "[{'label': 'POSITIVE', 'score': 0.9947445392608643}]\n",
            "[{'label': 'POSITIVE', 'score': 0.9997355341911316}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.695769727230072}]\n",
            "[{'label': 'POSITIVE', 'score': 0.9950939416885376}]\n",
            "[{'label': 'POSITIVE', 'score': 0.9998761415481567}]\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline('sentiment-analysis', model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "print(classifier(\"BERT is amazing!\"))\n",
        "print(classifier(\"BERT is awful!\"))\n",
        "print(classifier(\"I will find you and I'll kill you!\"))\n",
        "\n",
        "print(classifier(\"As High as Honor.\"))\n",
        "print(classifier(\"Ours is the fury.\"))\n",
        "print(classifier(\"Winter is coming.\"))\n",
        "print(classifier(\"Growing strong.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nYUNuyXMn5l9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'arryn': True, 'baratheon': False, 'stark': True, 'tyrell': True}\n",
            "dict_values([True, False, True, True])\n",
            "Well done!\n"
          ]
        }
      ],
      "source": [
        "import base64\n",
        "data = {\n",
        "    'arryn': 'As High as Honor.',\n",
        "    'baratheon': 'Ours is the fury.',\n",
        "    'stark': 'Winter is coming.',\n",
        "    'tyrell': 'Growing strong.'\n",
        "}\n",
        "\n",
        "# YOUR CODE: predict sentiment for each noble house and create outputs dict\n",
        "# <...>\n",
        "# outputs = <YOUR CODE: dict (house name) : True if positive, False if negative>\n",
        "\n",
        "outputs = {k: True if classifier(data[k])[0]['label'] == 'POSITIVE' else False for k in data}\n",
        "print(outputs)\n",
        "print(outputs.values())\n",
        "\n",
        "assert sum(outputs.values()) == 3 and outputs[base64.decodebytes(b'YmFyYXRoZW9u\\n').decode()] == False\n",
        "print(\"Well done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRDhIH-XpSNo"
      },
      "source": [
        "You can also access vanilla Masked Language Model that was trained to predict masked words. Here's how:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pa-8noIllRbZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P=0.99719 donald trump is the president of the united states.\n",
            "P=0.00024 donald duck is the president of the united states.\n",
            "P=0.00022 donald ross is the president of the united states.\n",
            "P=0.00020 donald johnson is the president of the united states.\n",
            "P=0.00018 donald wilson is the president of the united states.\n"
          ]
        }
      ],
      "source": [
        "mlm_model = pipeline('fill-mask', model=\"bert-base-uncased\")\n",
        "MASK = mlm_model.tokenizer.mask_token\n",
        "\n",
        "for hypo in mlm_model(f\"Donald {MASK} is the president of the united states.\"):\n",
        "  print(f\"P={hypo['score']:.5f}\", hypo['sequence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9NxeG1Y5pwX1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'score': 0.7481589317321777,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': 'he is the greatest human!'},\n",
              " {'score': 0.11051268130540848,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': 'she is the greatest human!'},\n",
              " {'score': 0.02057752013206482,\n",
              "  'token': 2023,\n",
              "  'token_str': 'this',\n",
              "  'sequence': 'this is the greatest human!'},\n",
              " {'score': 0.014749483205378056,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': 'it is the greatest human!'},\n",
              " {'score': 0.007025654893368483,\n",
              "  'token': 2008,\n",
              "  'token_str': 'that',\n",
              "  'sequence': 'that is the greatest human!'}]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your turn: use bert to recall what year was the Soviet Union founded in\n",
        "mlm_model(f\"Soviet Union was founded in {MASK} .\")\n",
        "mlm_model(f\"Mask aligner is {MASK} in many labs .\")\n",
        "mlm_model(f\"{MASK} is the greatest human!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJxRFzCSq903"
      },
      "source": [
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "Huggingface offers hundreds of pre-trained models that specialize on different tasks. You can quickly find the model you need using [this list](https://huggingface.co/models).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HRux8Qp2hkXr"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Almost two-thirds of the 1.5 million people who viewed this liveblog had Googled to discover\n",
        " the latest on the Rosetta mission. They were treated to this detailed account by the Guardian’s science editor,\n",
        " Ian Sample, and astronomy writer Stuart Clark of the moment scientists landed a robotic spacecraft on a comet \n",
        " for the first time in history, and the delirious reaction it provoked at their headquarters in Germany.\n",
        "  “We are there. We are sitting on the surface. Philae is talking to us,” said one scientist.\n",
        "\"\"\"\n",
        "\n",
        "# Task: create a pipeline for named entity recognition, use task name 'ner' and search for the right model in the list\n",
        "# ner_model = <YOUR CODE>\n",
        "ner_model = pipeline('ner', model ='dslim/bert-base-NER')\n",
        "\n",
        "named_entities = ner_model(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hf57MRzSiSON"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OUTPUT: [{'entity': 'B-LOC', 'score': 0.7991047, 'index': 27, 'word': 'Rose', 'start': 112, 'end': 116}, {'entity': 'I-LOC', 'score': 0.95119274, 'index': 28, 'word': '##tta', 'start': 116, 'end': 119}, {'entity': 'B-ORG', 'score': 0.998223, 'index': 40, 'word': 'Guardian', 'start': 179, 'end': 187}, {'entity': 'B-PER', 'score': 0.9997613, 'index': 46, 'word': 'Ian', 'start': 207, 'end': 210}, {'entity': 'I-PER', 'score': 0.99978715, 'index': 47, 'word': 'Sam', 'start': 211, 'end': 214}, {'entity': 'I-PER', 'score': 0.99964595, 'index': 48, 'word': '##ple', 'start': 214, 'end': 217}, {'entity': 'B-PER', 'score': 0.9997831, 'index': 53, 'word': 'Stuart', 'start': 240, 'end': 246}, {'entity': 'I-PER', 'score': 0.9997482, 'index': 54, 'word': 'Clark', 'start': 247, 'end': 252}, {'entity': 'B-LOC', 'score': 0.9997228, 'index': 85, 'word': 'Germany', 'start': 414, 'end': 421}, {'entity': 'B-PER', 'score': 0.9963127, 'index': 99, 'word': 'Phil', 'start': 471, 'end': 475}, {'entity': 'I-PER', 'score': 0.9889253, 'index': 100, 'word': '##ae', 'start': 475, 'end': 477}]\n",
            "All tests passed\n"
          ]
        }
      ],
      "source": [
        "print('OUTPUT:', named_entities)\n",
        "word_to_entity = {item['word']: item['entity'] for item in named_entities}\n",
        "assert 'org' in word_to_entity.get('Guardian').lower() and 'per' in word_to_entity.get('Stuart').lower()\n",
        "print(\"All tests passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULMownz6sP9n"
      },
      "source": [
        "### The building blocks of a pipeline\n",
        "\n",
        "Huggingface also allows you to access its pipelines on a lower level. There are two main abstractions for you:\n",
        "* `Tokenizer` - converts from strings to token ids and back\n",
        "* `Model` - a pytorch `nn.Module` with pre-trained weights\n",
        "\n",
        "You can use such models as part of your regular pytorch code: insert is as a layer in your model, apply it to a batch of data, backpropagate, optimize, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMJbV0QVsO0Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, pipeline\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgSPHKPRxG6U"
      },
      "outputs": [],
      "source": [
        "lines = [\n",
        "    \"Luke, I am your father.\",\n",
        "    \"Life is what happens when you're busy making other plans.\",\n",
        "    ]\n",
        "\n",
        "# tokenize a batch of inputs. \"pt\" means [p]y[t]orch tensors\n",
        "tokens_info = tokenizer(lines, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "for key in tokens_info:\n",
        "    print(key, tokens_info[key])\n",
        "\n",
        "print(\"Detokenized:\")\n",
        "for i in range(2):\n",
        "    print(tokenizer.decode(tokens_info['input_ids'][i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[tokenizer.decode(int(i)) for i in tokens_info['input_ids'][1].data.numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJkbHxERyfL4"
      },
      "outputs": [],
      "source": [
        "# You can now apply the model to get embeddings\n",
        "with torch.no_grad():\n",
        "    # token_embeddings, sentence_embedding = model(**tokens_info)\n",
        "    out = model(**tokens_info)\n",
        "\n",
        "# print(sentence_embedding)\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMpzCoIL0Mmw"
      },
      "source": [
        "### The search for similar questions.\n",
        "\n",
        "Remeber week01 where you used GloVe embeddings to find related questions? That was.. cute, but far from state of the art. It's time to **really** solve this task using context-aware embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziLqtAcD3CXX"
      },
      "outputs": [],
      "source": [
        "# download the data:\n",
        "!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt\n",
        "# alternative download link: https://yadi.sk/i/BPQrUu1NaTduEw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmKr7Eza3PZ6"
      },
      "source": [
        "__Main task(3 pts):__ \n",
        "* Implement a function that takes a text string and finds top-k most similar questions from `quora.txt`\n",
        "* Demonstrate your function using at least 5 examples\n",
        "\n",
        "There are no prompts this time: you will have to write everything from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsr4Jr0gzPvf"
      },
      "outputs": [],
      "source": [
        "# <A whole lot of your code. Feel free to format it as you see fit>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"What TV shows or books help you read people's body language?\\n\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = list(open(\"./quora.txt\", encoding=\"utf-8\"))\n",
        "data[50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sentence-transformers) (1.2.1)\n",
            "Requirement already satisfied: torchvision in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\n",
            "Requirement already satisfied: nltk in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sentence-transformers) (0.1.97)\n",
            "Requirement already satisfied: tqdm in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sentence-transformers) (0.13.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sentence-transformers) (4.27.0)\n",
            "Requirement already satisfied: scipy in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: numpy in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sentence-transformers) (1.24.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: filelock in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: requests in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.91)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n",
            "Requirement already satisfied: sympy in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.101)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.14.3)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: networkx in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.0)\n",
            "Requirement already satisfied: jinja2 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.4.91)\n",
            "Requirement already satisfied: setuptools in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (65.6.3)\n",
            "Requirement already satisfied: wheel in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (0.37.1)\n",
            "Requirement already satisfied: lit in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (15.0.7)\n",
            "Requirement already satisfied: cmake in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.26.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n",
            "Requirement already satisfied: click in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 6.76569119e-02  6.34959117e-02  4.87131104e-02  7.93049857e-02\n",
            "   3.74480635e-02  2.65278947e-03  3.93749550e-02 -7.09845126e-03\n",
            "   5.93614280e-02  3.15370224e-02  6.00980595e-02 -5.29051945e-02\n",
            "   4.06067967e-02 -2.59308480e-02  2.98428312e-02  1.12691941e-03\n",
            "   7.35149086e-02 -5.03819585e-02 -1.22386619e-01  2.37028524e-02\n",
            "   2.97264922e-02  4.24768627e-02  2.56337821e-02  1.99517142e-03\n",
            "  -5.69190606e-02 -2.71598138e-02 -3.29035632e-02  6.60248771e-02\n",
            "   1.19007140e-01 -4.58791219e-02 -7.26214647e-02 -3.25839818e-02\n",
            "   5.23413792e-02  4.50552814e-02  8.25301930e-03  3.67023796e-02\n",
            "  -1.39415115e-02  6.53919131e-02 -2.64272355e-02  2.06399694e-04\n",
            "  -1.36643350e-02 -3.62810381e-02 -1.95043776e-02 -2.89738197e-02\n",
            "   3.94270197e-02 -8.84090737e-02  2.62426492e-03  1.36713926e-02\n",
            "   4.83063087e-02 -3.11565641e-02 -1.17329188e-01 -5.11690117e-02\n",
            "  -8.85288119e-02 -2.18962412e-02  1.42986597e-02  4.44168150e-02\n",
            "  -1.34815276e-02  7.43392482e-02  2.66382881e-02 -1.98762510e-02\n",
            "   1.79191362e-02 -1.06052533e-02 -9.04263258e-02  2.13269573e-02\n",
            "   1.41204894e-01 -6.47174846e-03 -1.40387274e-03 -1.53610036e-02\n",
            "  -8.73571932e-02  7.22174123e-02  2.01403312e-02  4.25587483e-02\n",
            "  -3.49013954e-02  3.19571700e-04 -8.02970678e-02 -3.27472501e-02\n",
            "   2.85268184e-02 -5.13658002e-02  1.09389201e-01  8.19327980e-02\n",
            "  -9.84039679e-02 -9.34095532e-02 -1.51292169e-02  4.51248549e-02\n",
            "   4.94172014e-02 -2.51867902e-02  1.57077443e-02 -1.29290774e-01\n",
            "   5.31891966e-03  4.02344111e-03 -2.34572385e-02 -6.72983006e-02\n",
            "   2.92281024e-02 -2.60845236e-02  1.30625237e-02 -3.11662946e-02\n",
            "  -4.82713617e-02 -5.58859557e-02 -3.87505405e-02  1.20010786e-01\n",
            "  -1.03924377e-02  4.89705130e-02  5.53536937e-02  4.49358821e-02\n",
            "  -4.00970643e-03 -1.02959730e-01 -2.92968787e-02 -5.83402142e-02\n",
            "   2.70472392e-02 -2.20169555e-02 -7.22241253e-02 -4.13869582e-02\n",
            "  -1.93297993e-02  2.73330859e-03  2.76938896e-04 -9.67588276e-02\n",
            "  -1.00574732e-01 -1.41922748e-02 -8.07891563e-02  4.53925543e-02\n",
            "   2.45040935e-02  5.97613975e-02 -7.38185272e-02  1.19843790e-02\n",
            "  -6.63403571e-02 -7.69044980e-02  3.85157578e-02 -5.59362073e-33\n",
            "   2.80013699e-02 -5.60784750e-02 -4.86601964e-02  2.15569865e-02\n",
            "   6.01980649e-02 -4.81403247e-02 -3.50246914e-02  1.93314031e-02\n",
            "  -1.75151993e-02 -3.89210023e-02 -3.81063554e-03 -1.70288086e-02\n",
            "   2.82099731e-02  1.28290579e-02  4.71601114e-02  6.21030033e-02\n",
            "  -6.43588603e-02  1.29285648e-01 -1.31231369e-02  5.23069352e-02\n",
            "  -3.73680890e-02  2.89094336e-02 -1.68981291e-02 -2.37330645e-02\n",
            "  -3.33491974e-02 -5.16762957e-02  1.55356852e-02  2.08802968e-02\n",
            "  -1.25371227e-02  4.59578969e-02  3.72720361e-02  2.80567128e-02\n",
            "  -5.90005107e-02 -1.16988299e-02  4.92182262e-02  4.70328704e-02\n",
            "   7.35487267e-02 -3.70529927e-02  3.98461241e-03  1.06412275e-02\n",
            "  -1.61543765e-04 -5.27166314e-02  2.75927708e-02 -3.92921753e-02\n",
            "   8.44717771e-02  4.86860760e-02 -4.85872524e-03  1.79948583e-02\n",
            "  -4.28570062e-02  1.23375580e-02  6.39956631e-03  4.04822901e-02\n",
            "   1.48887318e-02 -1.53941214e-02  7.62947723e-02  2.37043500e-02\n",
            "   4.45237309e-02  5.08195423e-02 -2.31251633e-03 -1.88737363e-02\n",
            "  -1.23336082e-02  4.66002263e-02 -5.63438162e-02  6.29927367e-02\n",
            "  -3.15534920e-02  3.24912369e-02  2.34673228e-02 -6.55438006e-02\n",
            "   2.01709159e-02  2.57082526e-02 -1.23868398e-02 -8.36496055e-03\n",
            "  -6.64378181e-02  9.43074077e-02 -3.57092544e-02 -3.42483334e-02\n",
            "  -6.66354457e-03 -8.01527593e-03 -3.09711043e-02  4.33012508e-02\n",
            "  -8.21395498e-03 -1.50795028e-01  3.07692084e-02  4.00718786e-02\n",
            "  -3.79293710e-02  1.93212088e-03  4.00530323e-02 -8.77074823e-02\n",
            "  -3.68491523e-02  8.57954379e-03 -3.19251977e-02 -1.25257988e-02\n",
            "   7.35539198e-02  1.34737953e-03  2.05918960e-02  2.71098072e-33\n",
            "  -5.18577099e-02  5.78360818e-02 -9.18985531e-02  3.94421816e-02\n",
            "   1.05576538e-01 -1.96912494e-02  6.18402362e-02 -7.63464719e-02\n",
            "   2.40880456e-02  9.40049067e-02 -1.16535492e-01  3.71198505e-02\n",
            "   5.22425063e-02 -3.95854004e-03  5.72214685e-02  5.32855792e-03\n",
            "   1.24016829e-01  1.39022451e-02 -1.10249929e-02  3.56053337e-02\n",
            "  -3.30754705e-02  8.16574022e-02 -1.52003653e-02  6.05584867e-02\n",
            "  -6.01397082e-02  3.26102562e-02 -3.48296538e-02 -1.69881731e-02\n",
            "  -9.74907354e-02 -2.71483585e-02  1.74706965e-03 -7.68982172e-02\n",
            "  -4.31858376e-02 -1.89985689e-02 -2.91660875e-02  5.77488504e-02\n",
            "   2.41821725e-02 -1.16901826e-02 -6.21435009e-02  2.84351856e-02\n",
            "  -2.37524349e-04 -2.51783449e-02  4.39635990e-03  8.12840536e-02\n",
            "   3.64184678e-02 -6.04006201e-02 -3.65517549e-02 -7.93748349e-02\n",
            "  -5.08527784e-03  6.69699088e-02 -1.17784373e-01  3.23743634e-02\n",
            "  -4.71252128e-02 -1.34459967e-02 -9.48445052e-02  8.24948866e-03\n",
            "  -1.06748547e-02 -6.81881905e-02  1.11812912e-03  2.48020049e-02\n",
            "  -6.35889545e-02  2.84492970e-02 -2.61303317e-02  8.58111084e-02\n",
            "   1.14682280e-01 -5.35345897e-02 -5.63588738e-02  4.26009037e-02\n",
            "   1.09454105e-02  2.09578704e-02  1.00131199e-01  3.26051265e-02\n",
            "  -1.84208810e-01 -3.93208340e-02 -6.91454709e-02 -6.38105273e-02\n",
            "  -6.56385869e-02 -6.41250657e-03 -4.79612462e-02 -7.68133178e-02\n",
            "   2.95384377e-02 -2.29948349e-02  4.17036675e-02 -2.50047483e-02\n",
            "  -4.54507675e-03 -4.17136699e-02 -1.32289445e-02 -6.38357624e-02\n",
            "  -2.46473309e-03 -1.37337651e-02  1.68976765e-02 -6.30398318e-02\n",
            "   8.98880959e-02  4.18170765e-02 -1.85687505e-02 -1.80442150e-08\n",
            "  -1.67998336e-02 -3.21577750e-02  6.30383790e-02 -4.13092114e-02\n",
            "   4.44819257e-02  2.02468690e-03  6.29592687e-02 -5.17373718e-03\n",
            "  -1.00444043e-02 -3.05640474e-02  3.52672599e-02  5.58581688e-02\n",
            "  -4.67125066e-02  3.45102921e-02  3.29577774e-02  4.30114232e-02\n",
            "   2.94361431e-02 -3.03164516e-02 -1.71107650e-02  7.37485066e-02\n",
            "  -5.47909774e-02  2.77515333e-02  6.20164443e-03  1.58800725e-02\n",
            "   3.42978612e-02 -5.15751075e-03  2.35079695e-02  7.53135309e-02\n",
            "   1.92843340e-02  3.36196609e-02  5.09103388e-02  1.52497113e-01\n",
            "   1.64207630e-02  2.70528495e-02  3.75162363e-02  2.18553450e-02\n",
            "   5.66334017e-02 -3.95747125e-02  7.12313280e-02 -5.41377254e-02\n",
            "   1.03772944e-03  2.11853292e-02 -3.56309004e-02  1.09017007e-01\n",
            "   2.76526227e-03  3.13997380e-02  1.38420740e-03 -3.45738605e-02\n",
            "  -4.59277742e-02  2.88083497e-02  7.16904784e-03  4.84684855e-02\n",
            "   2.61018239e-02 -9.44074616e-03  2.82169357e-02  3.48724015e-02\n",
            "   3.69098559e-02 -8.58947821e-03 -3.53205800e-02 -2.47857217e-02\n",
            "  -1.91921089e-02  3.80707681e-02  5.99654242e-02 -4.22286913e-02]\n",
            " [ 8.64385739e-02  1.02762610e-01  5.39457379e-03  2.04441813e-03\n",
            "  -9.96337086e-03  2.53855027e-02  4.92875725e-02 -3.06265987e-02\n",
            "   6.87254667e-02  1.01365875e-02  7.75397718e-02 -9.00807232e-02\n",
            "   6.10616338e-03 -5.69899008e-02  1.41714998e-02  2.80491374e-02\n",
            "  -8.68464410e-02  7.64398947e-02 -1.03491299e-01 -6.77437857e-02\n",
            "   6.99946955e-02  8.44251141e-02 -7.24915741e-03  1.04770651e-02\n",
            "   1.34020764e-02  6.77576661e-02 -9.42086279e-02 -3.71689983e-02\n",
            "   5.22617698e-02 -3.10853459e-02 -9.63406935e-02  1.57717112e-02\n",
            "   2.57866718e-02  7.85244703e-02  7.89949596e-02  1.91516690e-02\n",
            "   1.64356679e-02  3.10081709e-03  3.81311513e-02  2.37090625e-02\n",
            "   1.05389664e-02 -4.40645106e-02  4.41738218e-02 -2.58727763e-02\n",
            "   6.15378618e-02 -4.05427590e-02 -8.64140391e-02  3.19722705e-02\n",
            "  -8.90729076e-04 -2.44436823e-02 -9.19721350e-02  2.33939644e-02\n",
            "  -8.30293521e-02  4.41510305e-02 -2.49692742e-02  6.23020232e-02\n",
            "  -1.30351761e-03  7.51395449e-02  2.46385094e-02 -6.47244379e-02\n",
            "  -1.17727816e-01  3.83392014e-02 -9.11767334e-02  6.35446236e-02\n",
            "   7.62739405e-02 -8.80241543e-02  9.54557490e-03 -4.69717756e-02\n",
            "  -8.41740966e-02  3.88823338e-02 -1.14393555e-01  6.28858944e-03\n",
            "  -3.49361524e-02  2.39750594e-02 -3.31317037e-02 -1.57244429e-02\n",
            "  -3.78955491e-02 -8.81248061e-03  7.06118718e-02  3.28066237e-02\n",
            "   2.03676126e-03 -1.12278961e-01  6.79718982e-03  1.22765480e-02\n",
            "   3.35303508e-02 -1.36200478e-02 -2.25490052e-02 -2.25228872e-02\n",
            "  -2.03194208e-02  5.04297428e-02 -7.48652965e-02 -8.22822377e-02\n",
            "   7.65962675e-02  4.93392460e-02 -3.75553481e-02  1.44634647e-02\n",
            "  -5.72457463e-02 -1.79954097e-02  1.09697953e-01  1.19462743e-01\n",
            "   8.09232122e-04  6.17057756e-02  3.26322727e-02 -1.30780101e-01\n",
            "  -1.48636639e-01 -6.16233014e-02  4.33886088e-02  2.67129391e-02\n",
            "   1.39786070e-02 -3.94002683e-02 -2.52711587e-02  3.87741416e-03\n",
            "   3.58664691e-02 -6.15420602e-02  3.76660787e-02  2.67565083e-02\n",
            "  -3.82659324e-02 -3.54793482e-02 -2.39227526e-02  8.67977515e-02\n",
            "  -1.84063241e-02  7.71039575e-02  1.39866723e-03  7.00383112e-02\n",
            "  -4.77877855e-02 -7.89820030e-02  5.10814264e-02 -2.99868444e-33\n",
            "  -3.91646288e-02 -2.56210798e-03  1.65210571e-02  9.48937330e-03\n",
            "  -5.66219203e-02  6.57782927e-02 -4.77002747e-02  1.11661833e-02\n",
            "  -5.73558472e-02 -9.16258153e-03 -2.17521340e-02 -5.59531711e-02\n",
            "  -1.11423088e-02  9.32793394e-02  1.66765042e-02 -1.36723546e-02\n",
            "   4.34388481e-02  1.87245966e-03  7.29953032e-03  5.16332202e-02\n",
            "   4.80608679e-02  1.35341495e-01 -1.71739236e-02 -1.29698142e-02\n",
            "  -7.50109628e-02  2.61107944e-02  2.69802082e-02  7.83087977e-04\n",
            "  -4.87269983e-02  1.17842797e-02 -4.59580347e-02 -4.83213626e-02\n",
            "  -1.95670947e-02  1.93889141e-02  1.98807269e-02  1.67432334e-02\n",
            "   9.87801179e-02 -2.74088010e-02  2.34808810e-02  3.70231015e-03\n",
            "  -6.14514649e-02 -1.21230423e-03 -9.50473454e-03  9.25154518e-03\n",
            "   2.38443762e-02  8.61232057e-02  2.26790085e-02  5.45131508e-04\n",
            "   3.47130299e-02  6.25461293e-03 -6.92775892e-03  3.92400771e-02\n",
            "   1.15675023e-02  3.26279737e-02  6.22155517e-02  2.76114345e-02\n",
            "   1.86883807e-02  3.55805494e-02  4.11795676e-02  1.54781882e-02\n",
            "   4.22691479e-02  3.82248312e-02  1.00313444e-02 -2.83246152e-02\n",
            "   4.47052419e-02 -4.10458781e-02 -4.50546481e-03 -5.44734336e-02\n",
            "   2.62321047e-02  1.79862324e-02 -1.23118781e-01 -4.66952100e-02\n",
            "  -1.35913091e-02  6.46710545e-02  3.57351801e-03 -1.22234141e-02\n",
            "  -1.79382581e-02 -2.55502164e-02  2.37224475e-02  4.08667233e-03\n",
            "  -6.51475638e-02  4.43651900e-02  4.68595996e-02 -3.25174816e-02\n",
            "   4.02271887e-03 -3.97602795e-03  1.11939581e-02 -9.95597765e-02\n",
            "   3.33168507e-02  8.01061019e-02  9.42692459e-02 -6.38294071e-02\n",
            "   3.23151313e-02 -5.13553694e-02 -7.49877887e-03  5.30049321e-34\n",
            "  -4.13194895e-02  9.49646607e-02 -1.06401466e-01  4.96590659e-02\n",
            "  -3.41913737e-02 -3.16746011e-02 -1.71555877e-02  1.70102820e-03\n",
            "   5.79758286e-02 -1.21777237e-03 -1.68536305e-02 -5.16912602e-02\n",
            "   5.52998520e-02 -3.42647471e-02  3.08179222e-02 -3.10481116e-02\n",
            "   9.27532613e-02  3.72663848e-02 -2.37397812e-02  4.45893593e-02\n",
            "   1.46153681e-02  1.16239347e-01 -5.00112772e-02  3.88716459e-02\n",
            "   4.24750149e-03  2.56976467e-02  3.27243656e-02  4.29907814e-02\n",
            "  -1.36144394e-02  2.56122239e-02  1.06262295e-02 -8.46864209e-02\n",
            "  -9.52982157e-02  1.08399883e-01 -7.51600266e-02 -1.37773901e-02\n",
            "   6.37337789e-02 -4.49668290e-03 -3.25321220e-02  6.23613857e-02\n",
            "   3.48052718e-02 -3.54922190e-02 -2.00222339e-02  3.66608314e-02\n",
            "  -2.48837043e-02  1.01819076e-02 -7.01232851e-02 -4.31950875e-02\n",
            "   2.95332633e-02 -2.95002566e-04 -3.45386341e-02  1.46675762e-02\n",
            "  -9.83970016e-02 -4.70488295e-02 -8.85496475e-03 -8.89914110e-02\n",
            "   3.50995809e-02 -1.29602000e-01 -4.98866141e-02 -6.12047464e-02\n",
            "  -5.97797111e-02  9.46321804e-03  4.91217822e-02 -7.75026605e-02\n",
            "   8.09726864e-02 -4.79257330e-02  2.34379782e-03  7.57031217e-02\n",
            "  -2.40175519e-02 -1.52546139e-02  4.86738607e-02 -3.85969207e-02\n",
            "  -7.04831555e-02 -1.20348334e-02 -3.88790481e-02 -7.76016936e-02\n",
            "  -1.07243797e-02  1.04188062e-02 -2.13753581e-02 -9.17386413e-02\n",
            "  -1.11344848e-02 -2.96066198e-02  2.46458277e-02  4.65711579e-03\n",
            "  -1.63449831e-02 -3.95219773e-02  7.73373693e-02 -2.84732897e-02\n",
            "  -3.69940023e-03  8.27665105e-02 -1.10408943e-02  3.13983783e-02\n",
            "   5.35093881e-02  5.75145893e-02 -3.17622200e-02 -1.52911284e-08\n",
            "  -7.99661428e-02 -4.76797223e-02 -8.59788805e-02  5.69616556e-02\n",
            "  -4.08866182e-02  2.23832354e-02 -4.64443676e-03 -3.80131118e-02\n",
            "  -3.10670901e-02 -1.07278097e-02  1.97698399e-02  7.76999164e-03\n",
            "  -6.09475700e-03 -3.86376306e-02  2.80272141e-02  6.78138286e-02\n",
            "  -2.35351138e-02  3.21747884e-02  8.02538730e-03 -2.39107106e-02\n",
            "  -1.22001313e-03  3.14599201e-02 -5.24924174e-02 -8.06815550e-03\n",
            "   3.14771337e-03  5.11496775e-02 -4.44104932e-02  6.36013299e-02\n",
            "   3.85084003e-02  3.30432728e-02 -4.18725377e-03  4.95592877e-02\n",
            "  -5.69605082e-02 -6.49711723e-03 -2.49793492e-02 -1.60866920e-02\n",
            "   6.62289411e-02 -2.06310451e-02  1.08045749e-01  1.68547034e-02\n",
            "   1.43812904e-02 -1.32127218e-02 -1.29387408e-01  6.95216432e-02\n",
            "  -5.55773191e-02 -6.75413683e-02 -5.45819104e-03 -6.13591680e-03\n",
            "   3.90841141e-02 -6.28779829e-02  3.74063589e-02 -1.16570983e-02\n",
            "   1.29150292e-02 -5.52495345e-02  5.16075753e-02 -4.30840254e-03\n",
            "   5.80247231e-02  1.86944902e-02  2.27810498e-02  3.21666151e-02\n",
            "   5.37978746e-02  7.02849180e-02  7.49312490e-02 -8.41774717e-02]]\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data_vectors = np.array([get_phrase_embedding(l) for l in data])\n",
        "data_vectors = model.encode(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 5.29168807e-02,  1.56224016e-02,  4.28081155e-02,  8.24510977e-02,\n",
              "       -4.42565344e-02,  4.34900187e-02, -1.05001703e-02, -8.61628130e-02,\n",
              "        8.16449465e-04, -1.21423215e-01,  6.56440482e-02, -1.67419296e-02,\n",
              "       -4.15178239e-02, -3.25913318e-02,  5.27058020e-02, -1.48751616e-01,\n",
              "        6.32438511e-02,  7.99805671e-02,  6.66677505e-02, -6.18607849e-02,\n",
              "       -2.31075753e-02, -3.88341099e-02,  9.50826041e-04,  1.23370858e-02,\n",
              "       -3.47167589e-02,  1.19227953e-02, -2.29910687e-02, -4.05294225e-02,\n",
              "       -3.67469117e-02, -2.93446891e-02,  5.39622530e-02, -5.96254356e-02,\n",
              "       -1.14789978e-02,  5.00036068e-02, -5.01460731e-02, -1.15877446e-02,\n",
              "        6.90763891e-02, -6.00012094e-02,  2.31682286e-02,  4.64344816e-03,\n",
              "        1.25187226e-02, -6.27211556e-02, -2.18027532e-02, -3.10064275e-02,\n",
              "        4.93833348e-02, -8.87878984e-02, -5.90049475e-02,  4.40719798e-02,\n",
              "        3.24760564e-02, -3.09204105e-02, -1.44695286e-02, -1.61288437e-02,\n",
              "        2.89997421e-02,  2.36615166e-03,  1.07944265e-01, -1.44667942e-02,\n",
              "       -6.05623517e-03,  8.60245973e-02,  7.16699213e-02,  1.95159428e-02,\n",
              "       -1.06099783e-03, -2.96416748e-02, -2.19233241e-02,  5.09123653e-02,\n",
              "        5.31315804e-03,  5.29776961e-02, -2.92547978e-02,  8.07664543e-03,\n",
              "       -3.12098814e-03,  8.09886977e-02, -2.61964556e-02, -4.10731025e-02,\n",
              "       -3.12426165e-02, -7.37861395e-02,  5.52788414e-02, -1.14054782e-02,\n",
              "       -3.89358401e-02, -7.97003806e-02, -8.52266894e-05,  3.75026427e-02,\n",
              "       -3.75840776e-02,  3.12934406e-02,  3.47165354e-02,  6.46963716e-02,\n",
              "       -4.00752425e-02, -4.25041700e-03, -5.10107055e-02,  3.67694609e-02,\n",
              "        1.82277628e-03, -3.95661891e-02,  2.73615979e-02, -7.89014623e-03,\n",
              "       -1.61034521e-02, -3.27342264e-02,  3.10905953e-03, -5.18971644e-02,\n",
              "       -1.43220685e-02, -1.05878472e-01, -7.52832666e-02,  1.36559810e-02,\n",
              "        1.04376627e-02,  4.50280681e-02,  2.85292137e-02,  6.60351887e-02,\n",
              "        6.68699294e-02,  2.71090865e-02,  8.80650245e-03,  2.71484852e-02,\n",
              "       -2.44615972e-02,  1.35592669e-02, -1.77669898e-02,  1.23979770e-01,\n",
              "       -2.59432737e-02,  1.19033102e-02, -4.63485420e-02,  3.23071331e-02,\n",
              "        3.27086188e-02, -2.44825557e-02,  7.19394162e-02,  7.90598094e-02,\n",
              "       -7.56341293e-02,  9.06884074e-02,  7.03579038e-02, -4.13379818e-02,\n",
              "        9.44141019e-03,  7.90922195e-02, -2.51624715e-02, -1.96249443e-33,\n",
              "       -4.67823111e-02, -1.64020751e-02,  6.78972760e-03, -2.43513216e-03,\n",
              "        3.36589701e-02,  1.81497075e-03,  6.98545128e-02,  2.22158171e-02,\n",
              "        6.58829287e-02,  4.57910448e-02,  5.18832840e-02, -2.50133332e-02,\n",
              "       -3.15158367e-02, -1.99764017e-02,  6.82134405e-02, -1.72162622e-01,\n",
              "       -6.30003884e-02,  1.89083554e-02,  3.83700579e-02, -4.79255244e-03,\n",
              "       -3.24699581e-02, -1.18318647e-01,  3.08716074e-02,  4.08463031e-02,\n",
              "        6.72319625e-03, -4.58075218e-02, -1.00113614e-03, -5.76441027e-02,\n",
              "        9.99767706e-02,  3.43150832e-02, -1.80723257e-02,  5.97681664e-02,\n",
              "       -2.46327631e-02, -4.75786887e-02, -5.27127460e-02, -2.96814758e-02,\n",
              "        1.81730315e-02, -4.12212731e-03, -9.32699963e-02, -2.01727860e-02,\n",
              "       -4.53574993e-02,  2.16512904e-02, -8.71402305e-03, -1.25796814e-02,\n",
              "       -1.93251949e-03,  4.11226004e-02,  8.26314185e-03, -4.27569449e-02,\n",
              "       -4.94009294e-02,  3.33476514e-02, -1.87977729e-03, -5.10132462e-02,\n",
              "       -3.37185413e-02, -7.94083923e-02, -8.03233534e-02, -1.05211735e-01,\n",
              "       -3.21062058e-02, -8.51152018e-02,  1.00634964e-02, -1.66765731e-02,\n",
              "        2.53087226e-02,  3.62432525e-02, -7.79022574e-02,  7.93482512e-02,\n",
              "       -7.84038566e-03,  3.95570733e-02,  1.57698663e-03, -9.46806967e-02,\n",
              "       -4.39281352e-02,  4.44386937e-02,  4.56935093e-02, -3.29548158e-02,\n",
              "        1.03916749e-02, -4.89039123e-02, -2.16417648e-02, -3.00730020e-02,\n",
              "       -6.57988787e-02, -5.61492257e-02, -7.87910298e-02, -4.26645651e-02,\n",
              "        2.51495875e-02, -5.27520441e-02,  2.35219765e-02,  4.74276952e-02,\n",
              "        1.47029739e-02,  9.16424245e-02, -7.15728775e-02, -4.27336469e-02,\n",
              "        8.41815621e-02, -2.83490457e-02, -6.09313548e-02, -9.08701587e-03,\n",
              "        5.67075908e-02, -2.65760645e-02, -9.28406939e-02,  1.26614581e-33,\n",
              "        3.03333290e-02, -2.39478555e-02,  9.14638489e-02, -2.28365939e-02,\n",
              "        1.45502035e-02, -6.87912107e-02, -7.34466091e-02,  9.06949304e-03,\n",
              "        4.14236560e-02, -6.58865720e-02, -7.68340155e-02,  5.44547401e-02,\n",
              "        3.23645137e-02,  2.26140656e-02, -1.72320474e-02,  3.06598693e-02,\n",
              "        4.16691639e-02,  5.65764084e-02, -5.12101203e-02, -3.10228653e-02,\n",
              "       -2.89940052e-02,  1.99952703e-02, -1.56930517e-02,  4.17166986e-02,\n",
              "       -9.26957931e-03,  6.10124655e-02,  1.65966563e-02,  5.85039891e-02,\n",
              "       -7.84015954e-02, -2.19273008e-02,  2.30542161e-02,  5.09791858e-02,\n",
              "        7.35422969e-03, -4.75817993e-02,  4.17703576e-02,  8.05705041e-02,\n",
              "       -5.68102151e-02,  4.92847040e-02, -6.29433692e-02,  6.23386689e-02,\n",
              "        4.82603945e-02, -5.19453250e-02, -2.19932720e-02,  8.09693485e-02,\n",
              "        1.80130620e-02,  6.64007384e-03,  4.61050570e-02, -8.08866471e-02,\n",
              "        3.16963787e-03,  5.61284348e-02,  4.18826304e-02, -4.99068201e-02,\n",
              "        6.97223470e-02,  6.22771941e-02,  8.08629915e-02, -1.07656782e-02,\n",
              "        3.38147022e-02, -9.23212171e-02, -3.51548865e-02, -7.72979334e-02,\n",
              "       -6.06319718e-02, -4.82444763e-02,  5.75695001e-02,  9.49939117e-02,\n",
              "        1.56782255e-01, -1.13537751e-01, -2.69274600e-02, -4.21229042e-02,\n",
              "       -6.90167258e-03,  2.25937981e-02, -2.92623248e-02,  3.57484259e-02,\n",
              "        6.03021048e-02,  2.46666670e-02, -4.54986431e-02, -6.31017312e-02,\n",
              "       -8.04456994e-02,  6.14612363e-02, -2.37665381e-02, -5.70086949e-02,\n",
              "        2.33160637e-04,  2.05553770e-02,  2.97123846e-02, -3.82159464e-02,\n",
              "       -7.09230676e-02,  5.70446439e-02, -5.39846206e-03, -2.38961466e-02,\n",
              "        4.45019193e-02,  8.32471922e-02, -2.32855510e-02, -7.53684901e-03,\n",
              "       -1.57421678e-02,  5.83793782e-02,  5.14944382e-02, -1.60466076e-08,\n",
              "        9.34770629e-02, -1.16663270e-01, -2.58496515e-02,  4.27081957e-02,\n",
              "        5.11245765e-02,  5.60160093e-02, -6.06200062e-02,  4.77826223e-02,\n",
              "        2.24610884e-03, -1.27860261e-02, -1.69749316e-02,  6.06905632e-02,\n",
              "        4.82088178e-02,  2.54610628e-02, -1.44516351e-02, -3.20273824e-02,\n",
              "        7.87059069e-02,  6.55792207e-02, -2.67263427e-02,  8.11900869e-02,\n",
              "       -3.33825015e-02,  1.54305948e-02,  2.09740493e-02, -9.15786847e-02,\n",
              "        3.75603251e-02,  1.56844966e-02,  4.76032682e-02,  3.28307897e-02,\n",
              "        5.97329289e-02,  5.79247922e-02,  1.00980364e-02, -8.29377100e-02,\n",
              "       -3.75275016e-02,  1.87534362e-03, -3.02238874e-02, -3.63798738e-02,\n",
              "        2.44037416e-02,  9.63257998e-03, -2.35789642e-02, -4.71741818e-02,\n",
              "       -7.57602975e-02,  6.71135485e-02, -3.52989812e-03,  6.44564331e-02,\n",
              "       -5.58526292e-02,  6.54308274e-02, -3.93295400e-02,  1.17980018e-01,\n",
              "        1.97507348e-02,  3.34462635e-02, -3.61824669e-02,  6.15463667e-02,\n",
              "        7.77263343e-02, -5.43645164e-03, -8.03145319e-02,  9.24239215e-03,\n",
              "        2.08020918e-02,  7.34545989e-03,  1.44684976e-02,  3.56022990e-03,\n",
              "        5.70453741e-02,  1.76966917e-02, -4.87652570e-02,  3.04171909e-02],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_vectors.shape\n",
        "data_vectors[1,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_nearest(query, k=10):\n",
        "    \"\"\"\n",
        "    given text line (query), return k most similar lines from data, sorted from most to least similar\n",
        "    similarity should be measured as cosine between query and line embedding vectors\n",
        "    hint: it's okay to use global variables: data and data_vectors. see also: np.argpartition, np.argsort\n",
        "    \"\"\"\n",
        "    # YOUR CODE\n",
        "    \n",
        "    query_embedding = model.encode(query)\n",
        "    query_norm = np.linalg.norm(query_embedding)\n",
        "    cosins = []\n",
        "    for vec in data_vectors:\n",
        "        vec_norm = np.linalg.norm(vec)  \n",
        "        cosin = (query_embedding @ vec) / (vec_norm * query_norm)\n",
        "        cosins.append(cosin)\n",
        "\n",
        "    args = np.argsort(cosins)[::-1][2:k+2]\n",
        "    print(f\"{args}\")\n",
        "    \n",
        "    return [data[i] for i in args]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[195289  87199 231348 415628 128022  39464 259923 516438 289747 145469]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['How can this matrix be written in [math]\\\\LaTeX[/math]?\\n',\n",
              " 'How do I write an algorithm that compute matrix?\\n',\n",
              " 'What is The Matrix about?\\n',\n",
              " 'How do you multiply matrices?\\n',\n",
              " 'How do you multiply three matrices?\\n',\n",
              " 'How would you rotate a matrix?\\n',\n",
              " 'What is the shortcut to finding an inverse of a square matrix?\\n',\n",
              " 'How would I solve this math problem using a matrix?\\n',\n",
              " 'What is a matrix?\\n',\n",
              " 'How do I do a matrix transpose in Go?\\n']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_nearest(query=\"How do i enter the matrix?\", k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 36971 180884  77623 472078 311696 499904 103444  10908 178919 221239]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['How can Trump win?\\n',\n",
              " 'How did Trump win the presidency?\\n',\n",
              " 'How is Donald Trump winning?\\n',\n",
              " 'How is Donald Trump as a businessman?\\n',\n",
              " 'How did Trump get Elected?\\n',\n",
              " 'How good is Donald Trump for America as President?\\n',\n",
              " 'What is Trump?\\n',\n",
              " 'How did trump become president?\\n',\n",
              " 'How did Donald Trump win the presidency?\\n',\n",
              " 'In what ways is Donald Trump good for U.S. politics?\\n']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_nearest(query=\"How does Trump?\", k=10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OHEC6o7uAfgQ"
      },
      "source": [
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "__Bonus demo:__ transformer language models. \n",
        "\n",
        "`/* No points awarded for this task, but its really cool, we promise :) */`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "\n",
        "def get_nucleous_index(probs, p : float):\n",
        "\n",
        "    sorted_probs, indices = torch.sort(torch.tensor(probs, requires_grad=False, dtype=torch.float64), dim=-1, descending=True)\n",
        "    cum_sum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
        "\n",
        "    if cum_sum_probs[0] > p:\n",
        "        return indices[0]\n",
        "    \n",
        "    sorted_probs[cum_sum_probs > p] = 0\n",
        "    sorted_probs /= torch.sum(sorted_probs, dim=-1)\n",
        "\n",
        "    return random.choices(indices, weights=sorted_probs)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5)\n"
          ]
        }
      ],
      "source": [
        "probs = [0.1, 0.12, 0.05, 0.03, 0.32, 0.21, 0.01]\n",
        "# probs = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "p = 0.8\n",
        "print(get_nucleous_index(probs, p))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vWCajBGcAern"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            " The Fermi paradox  are highly plausible, and it's hard to believe that the two of them are\n",
            " not involved in a philosophical issue in which one of them was justly\n",
            " criticized.  I'm not saying that one of them is wrong, but that one of\n",
            " them is not important.  I don't think that this conclusion is wholly dis\n",
            "putable.  I think that there is a problem with this conclusion, and that\n",
            " it is very hard to reconcile with our actual understanding of  Cosmos\n",
            "  .  It is more plausible that he has a legitimate argument for an  int\n",
            "ended but not justified way of considering the two phenomena. "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', add_prefix_space=True)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2').train(False).to(device)\n",
        "\n",
        "text = \"The Fermi paradox \"\n",
        "# text = \"Anastasia is a \"\n",
        "tokens = tokenizer.encode(text)\n",
        "num_steps = 128\n",
        "line_length, max_length = 0, 70\n",
        "p = 0.7\n",
        "\n",
        "print(end=tokenizer.decode(tokens))\n",
        "\n",
        "for i in range(num_steps):\n",
        "    with torch.no_grad():\n",
        "        logits = model(torch.as_tensor([tokens], device=device))[0]\n",
        "    p_next = torch.softmax(logits[0, -1, :], dim=-1).data.cpu().numpy()\n",
        "    next_token_index = get_nucleous_index(p_next, p)\n",
        "\n",
        "    tokens.append(int(next_token_index))\n",
        "    print(end=tokenizer.decode(tokens[-1]))\n",
        "    line_length += len(tokenizer.decode(tokens[-1]))\n",
        "    if line_length >= max_length:\n",
        "        line_length = 0\n",
        "        print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vij7Gc1wOaq"
      },
      "source": [
        "Transformers knowledge hub: https://huggingface.co/transformers/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "seminar.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
