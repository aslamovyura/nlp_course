{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fed133d-61b7-4ce6-8a44-fe98acf0eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f3a8fd1-25a9-426d-a6be-c93b750cbcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a53036-31ab-4374-bf15-a4dca17a7cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accept</td>\n",
       "      <td>$ 950k - $ 1.3 m is okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accept</td>\n",
       "      <td>$1.2m is a pretty good offer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accept</td>\n",
       "      <td>$7k for the system including the pump works fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accept</td>\n",
       "      <td>€12,000 is good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accept</td>\n",
       "      <td>1,550,000.00 usd is approved.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intent                                          utterance\n",
       "0  Accept                          $ 950k - $ 1.3 m is okay.\n",
       "1  Accept                      $1.2m is a pretty good offer.\n",
       "2  Accept  $7k for the system including the pump works fo...\n",
       "3  Accept                                   €12,000 is good.\n",
       "4  Accept                      1,550,000.00 usd is approved."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = f'intents.csv'\n",
    "# datapath = f'intents-without-none.csv'\n",
    "df = pd.read_csv(datapath)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5fa5e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Accept',\n",
    "    'AskForEquipmentInstallation',\n",
    "    'AskForInterest',\n",
    "    'AskForPrice',\n",
    "    'AskIfBuy',\n",
    "    'AskIfHaveEquipment',\n",
    "    'AskIfSell',\n",
    "    'Decline',\n",
    "    'DeclinePrice',\n",
    "    'DeclineToBuy',\n",
    "    'DeclineToSell',\n",
    "    'DoNotHaveEquipment',\n",
    "    'HaveDeinstalledEquipment',\n",
    "    'HaveEquipment',\n",
    "    'HaveInstalledEquipment',\n",
    "    'None',\n",
    "    'OfferPrice',\n",
    "    'WantDeal',\n",
    "    'WantToBuy',\n",
    "    'WantToSell'\n",
    "]\n",
    "\n",
    "label2id = {k: v for v, k in enumerate(labels)}\n",
    "\n",
    "# label_to_id = {\n",
    "#     'Accept':0,\n",
    "#     'AskForEquipmentInstallation':1,\n",
    "#     'AskForInterest':2,\n",
    "#     'AskForPrice':3,\n",
    "#     'AskIfBuy':4,\n",
    "#     'AskIfHaveEquipment':5,\n",
    "#     'AskIfSell':6,\n",
    "#     'Decline':7,\n",
    "#     'DeclinePrice':8,\n",
    "#     'DeclineToBuy':9,\n",
    "#     'DeclineToSell':10,\n",
    "#     'DoNotHaveEquipment':11,\n",
    "#     'HaveDeinstalledEquipment':12,\n",
    "#     'HaveEquipment':13,\n",
    "#     'HaveInstalledEquipment':14,\n",
    "#     'None':15,\n",
    "#     'OfferPrice':16,\n",
    "#     'WantDeal':17,\n",
    "#     'WantToBuy':18,\n",
    "#     'WantToSell':19\n",
    "# }\n",
    "\n",
    "id2label = {v: k for v, k in enumerate(labels)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfef1ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Accept',\n",
       " 1: 'AskForEquipmentInstallation',\n",
       " 2: 'AskForInterest',\n",
       " 3: 'AskForPrice',\n",
       " 4: 'AskIfBuy',\n",
       " 5: 'AskIfHaveEquipment',\n",
       " 6: 'AskIfSell',\n",
       " 7: 'Decline',\n",
       " 8: 'DeclinePrice',\n",
       " 9: 'DeclineToBuy',\n",
       " 10: 'DeclineToSell',\n",
       " 11: 'DoNotHaveEquipment',\n",
       " 12: 'HaveDeinstalledEquipment',\n",
       " 13: 'HaveEquipment',\n",
       " 14: 'HaveInstalledEquipment',\n",
       " 15: 'None',\n",
       " 16: 'OfferPrice',\n",
       " 17: 'WantDeal',\n",
       " 18: 'WantToBuy',\n",
       " 19: 'WantToSell'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a34381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>None</td>\n",
       "      <td>i would appreciate it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>Decline</td>\n",
       "      <td>no longer needs it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>WantToSell</td>\n",
       "      <td>i wanted to share this kla sp1 tbi with you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>DoNotHaveEquipment</td>\n",
       "      <td>our manager does not have the model you require.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>None</td>\n",
       "      <td>they asked us for our response by 3 pm cst.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  intent                                         utterance\n",
       "3697                None                            i would appreciate it.\n",
       "1439             Decline                               no longer needs it.\n",
       "6267          WantToSell      i wanted to share this kla sp1 tbi with you.\n",
       "2074  DoNotHaveEquipment  our manager does not have the model you require.\n",
       "4681                None       they asked us for our response by 3 pm cst."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab965eff-e1eb-416f-b80c-850554d8026c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='intent'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['intent']).size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5074c270-ed3e-4e1a-863d-71737c743cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# txt = \"Do you have this equipment?\"\n",
    "# encoded1 = tokenizer(txt, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "# print(encoded1['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbd7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [label2id[label] for label in df['intent']]\n",
    "        self.texts = [\n",
    "            tokenizer(text, \n",
    "                      padding='max_length', max_length = 512, truncation=True,\n",
    "                      return_tensors=\"pt\") for text in df['utterance']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c8a5d0f-80c3-42b3-9f06-ecfc3a21f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # self.linear = nn.Linear(768, 19)\n",
    "        self.linear = nn.Linear(768, len(labels))\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        # probs = self.softmax(final_layer)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa1f1cf7-65db-4966-9a55-ba26bd22ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs, batch_size):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd8a670d-c449-45fe-8f4c-9a5fb27855c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data, batch_size:int):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25d2231d-fef1-42cf-a73e-188cac932727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6342 65 65\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "# df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), [int(.8*len(df)), int(.9*len(df))])\n",
    "# df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), [int(.98*len(df)), int(.99*len(df))])\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), [int(.98*len(df)), int(.99*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30242239-de70-4c03-8f56-9f5ade43518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 3171/3171 [02:57<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  1.191 | Train Accuracy:  0.399 | Val Loss:  0.981 | Val Accuracy:  0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3171/3171 [02:57<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.924 | Train Accuracy:  0.531 | Val Loss:  0.766 | Val Accuracy:  0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3171/3171 [02:57<00:00, 17.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.710 | Train Accuracy:  0.673 | Val Loss:  0.559 | Val Accuracy:  0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3171/3171 [02:57<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.531 | Train Accuracy:  0.777 | Val Loss:  0.440 | Val Accuracy:  0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3171/3171 [02:57<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.392 | Train Accuracy:  0.852 | Val Loss:  0.340 | Val Accuracy:  0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3171/3171 [02:56<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.284 | Train Accuracy:  0.911 | Val Loss:  0.264 | Val Accuracy:  0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3171/3171 [02:56<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.199 | Train Accuracy:  0.944 | Val Loss:  0.203 | Val Accuracy:  0.908\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 7\n",
    "LR = 1e-6\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "model = BertClassifier()\n",
    "train(model, df_train, df_val, LR, EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccc00f0a-9a15-4942-9c9b-2f9789c8dd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.800\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, df_test, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c023f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ae122a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30503c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_text(model, sentence):\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    mask = text['attention_mask'].to(device)\n",
    "    input_id = text['input_ids'].to(device)\n",
    "\n",
    "    output = model(input_id, mask)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # print(output[0])\n",
    "\n",
    "        probs = {id2label[i]:prob for i, prob in enumerate(torch.softmax(output[0], dim=-1).cpu().numpy())}\n",
    "        sorted_probs = {k: v for k, v in sorted(probs.items(), key=lambda item: item[1], reverse=True)}\n",
    "        print(sorted_probs)\n",
    "\n",
    "        # label_id = output.argmax(dim=1)[0].item()\n",
    "        # label = ids_to_labels[label_id]\n",
    "        # print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4763b618",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate_one_text(model, \u001b[39m\"\u001b[39m\u001b[39mWhat is the price for this amat/applied materials unit.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"What is the price for this amat/applied materials unit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8618185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './model-dict.dat'\n",
    "# torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0941bc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AskForPrice': 0.825172, 'OfferPrice': 0.03205681, 'DeclinePrice': 0.021559052, 'WantToSell': 0.011354526, 'AskIfBuy': 0.01095999, 'None': 0.008494745, 'Accept': 0.008248007, 'AskForEquipmentInstallation': 0.0063196123, 'AskForInterest': 0.0063196123, 'AskIfHaveEquipment': 0.0063196123, 'AskIfSell': 0.0063196123, 'Decline': 0.0063196123, 'DeclineToBuy': 0.0063196123, 'DeclineToSell': 0.0063196123, 'DoNotHaveEquipment': 0.0063196123, 'HaveDeinstalledEquipment': 0.0063196123, 'HaveEquipment': 0.0063196123, 'HaveInstalledEquipment': 0.0063196123, 'WantDeal': 0.0063196123, 'WantToBuy': 0.0063196123}\n"
     ]
    }
   ],
   "source": [
    "path = './model-dict.dat'\n",
    "model1 = BertClassifier()\n",
    "model1.load_state_dict(torch.load(path))\n",
    "model1.eval()\n",
    "evaluate_one_text(model1, \"What is the price for this amat/applied materials unit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0525046a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd155f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Dict\n",
    "\n",
    "\n",
    "class IntentClassifierFull(nn.Module):\n",
    "\n",
    "    def __init__(self, bertModel):\n",
    "\n",
    "        super(IntentClassifierFull, self).__init__()\n",
    "\n",
    "        self.label2id = label2id\n",
    "        self.id2label = id2label\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "        self.model = bertModel\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # def forward(self, input: str) -> Dict[str, float]:\n",
    "    def forward(self, input):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoded = self.tokenizer(input, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\"),\n",
    "            # print(encoded[0])\n",
    "            output = self.model(encoded[0]['input_ids'], encoded[0]['attention_mask'])\n",
    "            # print(output)\n",
    "            probs = self.softmax(output)\n",
    "\n",
    "            # probs = {ids_to_labels[i]:prob for i, prob in enumerate(torch.softmax(output[0], dim=-1).cpu().numpy())}\n",
    "            # sorted_probs = {k: v for k, v in sorted(probs.items(), key=lambda item: item[1], reverse=True)}\n",
    "            # print(sorted_probs)\n",
    "\n",
    "        # return sorted_probs\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b629b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class IntentClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, bertModel):\n",
    "\n",
    "        super(IntentClassifier, self).__init__()\n",
    "\n",
    "        self.labels = labels\n",
    "        self.label2id = label2id\n",
    "        self.id2label = id2label\n",
    "        self.model = bertModel\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # def forward(self, input: str) -> Dict[str, float]:\n",
    "    def forward(self, input_ids, mask):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_ids, mask)\n",
    "            # print(output)\n",
    "            probs = self.softmax(output)\n",
    "\n",
    "            # probs = {ids_to_labels[i]:prob for i, prob in enumerate(torch.softmax(output[0], dim=-1).cpu().numpy())}\n",
    "            # sorted_probs = {k: v for k, v in sorted(probs.items(), key=lambda item: item[1], reverse=True)}\n",
    "            # print(sorted_probs)\n",
    "\n",
    "        # return sorted_probs\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9debc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Dict\n",
    "\n",
    "\n",
    "# class IntentClassifier(nn.Module):\n",
    "\n",
    "#     def __init__(self, bertModel):\n",
    "\n",
    "#         super(IntentClassifier, self).__init__()\n",
    "\n",
    "#         self.label2id = labels\n",
    "#         self.id2label = ids_to_labels\n",
    "#         self.model = bertModel\n",
    "#         self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "#     # def forward(self, input: str) -> Dict[str, float]:\n",
    "#     def forward(self, input_ids, mask) -> Dict[str, float]:\n",
    "\n",
    "#         # with torch.no_grad():\n",
    "#         output = self.model(input_ids, mask)\n",
    "\n",
    "#         probs = self.softmax(output)\n",
    "\n",
    "#         probs = {ids_to_labels[i]:prob for i, prob in enumerate(torch.softmax(output[0], dim=-1).cpu().detach().numpy())}\n",
    "#         sorted_probs = {k: v for k, v in sorted(probs.items(), key=lambda item: item[1], reverse=True)}\n",
    "#             # print(sorted_probs)\n",
    "\n",
    "#         # return sorted_probs\n",
    "#         return sorted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "52f0424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = IntentClassifier(model1.to('cpu')).to('cpu')\n",
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53393b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0104, 0.0534, 0.0131, 0.0104, 0.0174, 0.6832, 0.0216, 0.0104, 0.0104,\n",
       "         0.0104, 0.0104, 0.0306, 0.0104, 0.0422, 0.0104, 0.0104, 0.0104, 0.0104,\n",
       "         0.0136, 0.0104]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"Do you have this equipment?\"\n",
    "encoded = tokenizer(txt, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "model2(encoded[\"input_ids\"], encoded[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bac95f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './intent_classifier.dat'\n",
    "# torch.save(model2.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "968ea9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\"text\":\"Do you have this equipment?\"}\n",
    "# print(data[\"text\"])\n",
    "# model2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "766bb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_data = \"Do you have this equipment?\"\n",
    "# # arr = bytearray(string_data, 'utf-8').to(torch.uint8)\n",
    "# # print(arr)\n",
    "\n",
    "# arr = torch.tensor(bytearray(string_data, 'utf-8'), dtype=torch.int64)\n",
    "# model2(arr)\n",
    "\n",
    "\n",
    "# print(arr)\n",
    "\n",
    "# print(arr.dtype)\n",
    "# for a in arr:\n",
    "#     print(a)\n",
    "# np.array(string_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ddf9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2(\"Do you have this equipment?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f6c3d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.as_tensor(\"Do you have this equipment?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbed034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnx) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnx) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnx) (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53e1d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amap = {str(i): i for i in range(50)}\n",
    "# n = onnx.helper.make_node(\n",
    "#     'LabelEncoder',\n",
    "#     inputs=['X'],\n",
    "#     outputs=['Y'],\n",
    "#     keys_strings=amap.keys(),\n",
    "#     values_int64s=amap.values(), \n",
    "#     domain='ai.onnx.ml'\n",
    "# )\n",
    "\n",
    "# X = onnx.helper.make_tensor_value_info(\"X\", onnx.TensorProto.STRING, [None])\n",
    "# Y = onnx.helper.make_tensor_value_info(\"Y\", onnx.TensorProto.INT64, [None])\n",
    "\n",
    "# graph_def = onnx.helper.make_graph(\n",
    "#     nodes=[n],\n",
    "#     name=\"mapper\",\n",
    "#     inputs=[X],\n",
    "#     outputs=[Y]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac915cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(graph_def)\n",
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8de610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72230eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# input_names = ['input_ids', 'mask']\n",
    "# output_names = ['probs']\n",
    "\n",
    "# txt = \"Do you have this equipment?\"\n",
    "# encoded = tokenizer(txt, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "# dummy_inputs = {'input_ids': encoded['input_ids'], 'mask': encoded['attention_mask']}\n",
    "\n",
    "# model2.eval()\n",
    "\n",
    "# torch.onnx.export(model2,                 \n",
    "#                   args=dummy_inputs,\n",
    "#                   input_names=input_names,\n",
    "#                   output_names=output_names,\n",
    "#                   f=\"intent_classifier.onnx\",\n",
    "#                   opset_version=10,          # the ONNX version to export the model to\n",
    "#                   do_constant_folding=True  # whether to execute constant folding for optimization\n",
    "#                 #   dynamic_axes={'input_ids' : {0 : 'batch_size'},    # variable length axes\n",
    "#                 #                 'probs' : {0 : 'batch_size'}}\n",
    "#                 #   export_params=True,\n",
    "#                 #   verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ade76707",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxfile = \"intent_classifier.onnx\"\n",
    "modified_onnxfile = \"modified_model.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1de04fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_names = ['input_ids', 'mask']\n",
    "output_names = ['probs']\n",
    "\n",
    "txt = \"Do you have this equipment?\"\n",
    "encoded = tokenizer(txt, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "dummy_inputs = {'input_ids': encoded['input_ids'], 'mask': encoded['attention_mask']}\n",
    "\n",
    "\n",
    "model2.eval()\n",
    "\n",
    "torch.onnx.export(model2,                 \n",
    "                  args=dummy_inputs,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names,\n",
    "                  f=onnxfile,\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True  # whether to execute constant folding for optimization\n",
    "                #   dynamic_axes={'input_ids' : {0 : 'batch_size'},    # variable length axes\n",
    "                #                 'probs' : {0 : 'batch_size'}}\n",
    "                #   export_params=True,\n",
    "                #   verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396bf154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx_model = onnx.load(onnxfile)\n",
    "# graph = onnx_model.graph\n",
    "\n",
    "# pads = onnx.helper.make_tensor('avg_pads', onnx.TensorProto.INT64, [8], np.zeros(8, dtype=int))\n",
    "# graph.initializer.append(pads)\n",
    "# node = graph.node[584]\n",
    "# new_node = onnx.helper.make_node(\n",
    "#     'Pad',\n",
    "#     name='__Pad_584_fixed',\n",
    "#     inputs=['675', 'avg_pads'],\n",
    "#     outputs=['676'],\n",
    "#     mode='constant'\n",
    "# )\n",
    "# graph.node.remove(node)\n",
    "# graph.node.insert(584, new_node)\n",
    "# # Fix Equals (replace with Not)\n",
    "# node = graph.node[322]\n",
    "# new_node = onnx.helper.make_node(\n",
    "#     'Not',\n",
    "#     name='__Not__Equal_322',\n",
    "#     inputs=['412'],\n",
    "#     outputs=['414'],\n",
    "# )\n",
    "# graph.node.remove(node)\n",
    "# graph.node.insert(322, new_node)\n",
    "\n",
    "# onnx.checker.check_model(onnx_model)\n",
    "# onnx.save(onnx_model, onnxfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "086c0cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/model/bert/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/Constant_output_0']\n",
      "/model/bert/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/Constant_1_output_0']\n",
      "/model/bert/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/Constant_2_output_0']\n",
      "/model/bert/ConstantOfShape\n",
      "ConstantOfShape\n",
      "['/model/bert/Constant_2_output_0']\n",
      "['/model/bert/ConstantOfShape_output_0']\n",
      "/model/bert/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/Constant_3_output_0']\n",
      "/model/bert/Mul\n",
      "Mul\n",
      "['/model/bert/ConstantOfShape_output_0', '/model/bert/Constant_3_output_0']\n",
      "['/model/bert/Mul_output_0']\n",
      "/model/bert/Equal\n",
      "Equal\n",
      "['/model/bert/Constant_1_output_0', '/model/bert/Mul_output_0']\n",
      "['/model/bert/Equal_output_0']\n",
      "/model/bert/Where\n",
      "Where\n",
      "['/model/bert/Equal_output_0', '/model/bert/ConstantOfShape_output_0', '/model/bert/Constant_1_output_0']\n",
      "['/model/bert/Where_output_0']\n",
      "/model/bert/Expand\n",
      "Expand\n",
      "['/model/bert/Constant_output_0', '/model/bert/Where_output_0']\n",
      "['/model/bert/Expand_output_0']\n",
      "/model/bert/Unsqueeze\n",
      "Unsqueeze\n",
      "['mask']\n",
      "['/model/bert/Unsqueeze_output_0']\n",
      "/model/bert/Unsqueeze_1\n",
      "Unsqueeze\n",
      "['/model/bert/Unsqueeze_output_0']\n",
      "['/model/bert/Unsqueeze_1_output_0']\n",
      "/model/bert/Cast\n",
      "Cast\n",
      "['/model/bert/Unsqueeze_1_output_0']\n",
      "['/model/bert/Cast_output_0']\n",
      "/model/bert/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/Constant_4_output_0']\n",
      "/model/bert/Sub\n",
      "Sub\n",
      "['/model/bert/Constant_4_output_0', '/model/bert/Cast_output_0']\n",
      "['/model/bert/Sub_output_0']\n",
      "/model/bert/Constant_5\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/Constant_5_output_0']\n",
      "/model/bert/Mul_1\n",
      "Mul\n",
      "['/model/bert/Sub_output_0', '/model/bert/Constant_5_output_0']\n",
      "['/model/bert/Mul_1_output_0']\n",
      "/model/bert/embeddings/word_embeddings/Gather\n",
      "Gather\n",
      "['model.bert.embeddings.word_embeddings.weight', 'input_ids']\n",
      "['/model/bert/embeddings/word_embeddings/Gather_output_0']\n",
      "/model/bert/embeddings/token_type_embeddings/Gather\n",
      "Gather\n",
      "['model.bert.embeddings.token_type_embeddings.weight', '/model/bert/Expand_output_0']\n",
      "['/model/bert/embeddings/token_type_embeddings/Gather_output_0']\n",
      "/model/bert/embeddings/Add\n",
      "Add\n",
      "['/model/bert/embeddings/word_embeddings/Gather_output_0', '/model/bert/embeddings/token_type_embeddings/Gather_output_0']\n",
      "['/model/bert/embeddings/Add_output_0']\n",
      "/model/bert/embeddings/position_embeddings/Gather\n",
      "Gather\n",
      "['model.bert.embeddings.position_embeddings.weight', 'onnx::Gather_1354']\n",
      "['/model/bert/embeddings/position_embeddings/Gather_output_0']\n",
      "/model/bert/embeddings/Add_1\n",
      "Add\n",
      "['/model/bert/embeddings/Add_output_0', '/model/bert/embeddings/position_embeddings/Gather_output_0']\n",
      "['/model/bert/embeddings/Add_1_output_0']\n",
      "/model/bert/embeddings/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/embeddings/Add_1_output_0']\n",
      "['/model/bert/embeddings/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/embeddings/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/embeddings/Add_1_output_0', '/model/bert/embeddings/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/embeddings/LayerNorm/Sub_output_0']\n",
      "/model/bert/embeddings/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/embeddings/LayerNorm/Constant_output_0']\n",
      "/model/bert/embeddings/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/embeddings/LayerNorm/Sub_output_0', '/model/bert/embeddings/LayerNorm/Constant_output_0']\n",
      "['/model/bert/embeddings/LayerNorm/Pow_output_0']\n",
      "/model/bert/embeddings/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/embeddings/LayerNorm/Pow_output_0']\n",
      "['/model/bert/embeddings/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/embeddings/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/embeddings/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/embeddings/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/embeddings/LayerNorm/ReduceMean_1_output_0', '/model/bert/embeddings/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/embeddings/LayerNorm/Add_output_0']\n",
      "/model/bert/embeddings/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/embeddings/LayerNorm/Add_output_0']\n",
      "['/model/bert/embeddings/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/embeddings/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/embeddings/LayerNorm/Sub_output_0', '/model/bert/embeddings/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/embeddings/LayerNorm/Div_output_0']\n",
      "/model/bert/embeddings/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/embeddings/LayerNorm/Div_output_0', 'model.bert.embeddings.LayerNorm.weight']\n",
      "['/model/bert/embeddings/LayerNorm/Mul_output_0']\n",
      "/model/bert/embeddings/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/embeddings/LayerNorm/Mul_output_0', 'model.bert.embeddings.LayerNorm.bias']\n",
      "['/model/bert/embeddings/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/embeddings/LayerNorm/Add_1_output_0', 'onnx::MatMul_1355']\n",
      "['/model/bert/encoder/layer.0/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.0.attention.self.query.bias', '/model/bert/encoder/layer.0/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/embeddings/LayerNorm/Add_1_output_0', 'onnx::MatMul_1356']\n",
      "['/model/bert/encoder/layer.0/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.0.attention.self.key.bias', '/model/bert/encoder/layer.0/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.0/attention/self/key/Add_output_0', '/model/bert/encoder/layer.0/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/embeddings/LayerNorm/Add_1_output_0', 'onnx::MatMul_1362']\n",
      "['/model/bert/encoder/layer.0/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.0.attention.self.value.bias', '/model/bert/encoder/layer.0/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.0/attention/self/value/Add_output_0', '/model/bert/encoder/layer.0/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.0/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.0/attention/self/query/Add_output_0', '/model/bert/encoder/layer.0/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.0/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.0/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.0/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.0/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.0/attention/self/MatMul_output_0', '/model/bert/encoder/layer.0/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.0/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.0/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.0/attention/self/Softmax_output_0', '/model/bert/encoder/layer.0/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.0/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.0/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.0/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.0/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.0/attention/self/Reshape_3_output_0', 'onnx::MatMul_1377']\n",
      "['/model/bert/encoder/layer.0/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.0.attention.output.dense.bias', '/model/bert/encoder/layer.0/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.0/attention/output/dense/Add_output_0', '/model/bert/embeddings/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.0/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.0/attention/output/Add_output_0', '/model/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.0/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.0/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.0/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.0.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.0/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.0.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.0/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1378']\n",
      "['/model/bert/encoder/layer.0/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.0/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.0.intermediate.dense.bias', '/model/bert/encoder/layer.0/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.0/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.0/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.0/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.0/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1379']\n",
      "['/model/bert/encoder/layer.0/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.0/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.0.output.dense.bias', '/model/bert/encoder/layer.0/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.0/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.0/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.0/output/dense/Add_output_0', '/model/bert/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.0/output/Add_output_0']\n",
      "/model/bert/encoder/layer.0/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.0/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.0/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.0/output/Add_output_0', '/model/bert/encoder/layer.0/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.0/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.0/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.0/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.0/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.0/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.0/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.0/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.0/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.0/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.0/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.0/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.0.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.0/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.0.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1380']\n",
      "['/model/bert/encoder/layer.1/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.1.attention.self.query.bias', '/model/bert/encoder/layer.1/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1381']\n",
      "['/model/bert/encoder/layer.1/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.1.attention.self.key.bias', '/model/bert/encoder/layer.1/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.1/attention/self/key/Add_output_0', '/model/bert/encoder/layer.1/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1387']\n",
      "['/model/bert/encoder/layer.1/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.1.attention.self.value.bias', '/model/bert/encoder/layer.1/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.1/attention/self/value/Add_output_0', '/model/bert/encoder/layer.1/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.1/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.1/attention/self/query/Add_output_0', '/model/bert/encoder/layer.1/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.1/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.1/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.1/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.1/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.1/attention/self/MatMul_output_0', '/model/bert/encoder/layer.1/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.1/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.1/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.1/attention/self/Softmax_output_0', '/model/bert/encoder/layer.1/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.1/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.1/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.1/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.1/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.1/attention/self/Reshape_3_output_0', 'onnx::MatMul_1402']\n",
      "['/model/bert/encoder/layer.1/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.1.attention.output.dense.bias', '/model/bert/encoder/layer.1/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.1/attention/output/dense/Add_output_0', '/model/bert/encoder/layer.0/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.1/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.1/attention/output/Add_output_0', '/model/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.1/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.1/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.1/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.1.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.1/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.1.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.1/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1403']\n",
      "['/model/bert/encoder/layer.1/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.1/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.1.intermediate.dense.bias', '/model/bert/encoder/layer.1/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.1/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.1/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.1/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.1/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1404']\n",
      "['/model/bert/encoder/layer.1/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.1/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.1.output.dense.bias', '/model/bert/encoder/layer.1/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.1/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.1/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.1/output/dense/Add_output_0', '/model/bert/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.1/output/Add_output_0']\n",
      "/model/bert/encoder/layer.1/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.1/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.1/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.1/output/Add_output_0', '/model/bert/encoder/layer.1/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.1/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.1/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.1/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.1/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.1/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.1/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.1/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.1/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.1/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.1/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.1/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.1.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.1/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.1.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1405']\n",
      "['/model/bert/encoder/layer.2/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.2.attention.self.query.bias', '/model/bert/encoder/layer.2/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1406']\n",
      "['/model/bert/encoder/layer.2/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.2.attention.self.key.bias', '/model/bert/encoder/layer.2/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.2/attention/self/key/Add_output_0', '/model/bert/encoder/layer.2/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1412']\n",
      "['/model/bert/encoder/layer.2/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.2.attention.self.value.bias', '/model/bert/encoder/layer.2/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.2/attention/self/value/Add_output_0', '/model/bert/encoder/layer.2/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.2/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.2/attention/self/query/Add_output_0', '/model/bert/encoder/layer.2/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.2/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.2/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.2/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.2/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.2/attention/self/MatMul_output_0', '/model/bert/encoder/layer.2/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.2/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.2/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.2/attention/self/Softmax_output_0', '/model/bert/encoder/layer.2/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.2/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.2/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.2/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.2/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.2/attention/self/Reshape_3_output_0', 'onnx::MatMul_1427']\n",
      "['/model/bert/encoder/layer.2/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.2.attention.output.dense.bias', '/model/bert/encoder/layer.2/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.2/attention/output/dense/Add_output_0', '/model/bert/encoder/layer.1/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.2/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.2/attention/output/Add_output_0', '/model/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.2/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.2/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.2/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.2.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.2/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.2.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.2/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1428']\n",
      "['/model/bert/encoder/layer.2/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.2/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.2.intermediate.dense.bias', '/model/bert/encoder/layer.2/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.2/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.2/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.2/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.2/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1429']\n",
      "['/model/bert/encoder/layer.2/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.2/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.2.output.dense.bias', '/model/bert/encoder/layer.2/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.2/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.2/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.2/output/dense/Add_output_0', '/model/bert/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.2/output/Add_output_0']\n",
      "/model/bert/encoder/layer.2/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.2/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.2/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.2/output/Add_output_0', '/model/bert/encoder/layer.2/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.2/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.2/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.2/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.2/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.2/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.2/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.2/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.2/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.2/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.2/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.2/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.2.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.2/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.2.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1430']\n",
      "['/model/bert/encoder/layer.3/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.3.attention.self.query.bias', '/model/bert/encoder/layer.3/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1431']\n",
      "['/model/bert/encoder/layer.3/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.3.attention.self.key.bias', '/model/bert/encoder/layer.3/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.3/attention/self/key/Add_output_0', '/model/bert/encoder/layer.3/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1437']\n",
      "['/model/bert/encoder/layer.3/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.3.attention.self.value.bias', '/model/bert/encoder/layer.3/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.3/attention/self/value/Add_output_0', '/model/bert/encoder/layer.3/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.3/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.3/attention/self/query/Add_output_0', '/model/bert/encoder/layer.3/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.3/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.3/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.3/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.3/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.3/attention/self/MatMul_output_0', '/model/bert/encoder/layer.3/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.3/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.3/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.3/attention/self/Softmax_output_0', '/model/bert/encoder/layer.3/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.3/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.3/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.3/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.3/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.3/attention/self/Reshape_3_output_0', 'onnx::MatMul_1452']\n",
      "['/model/bert/encoder/layer.3/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.3.attention.output.dense.bias', '/model/bert/encoder/layer.3/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.3/attention/output/dense/Add_output_0', '/model/bert/encoder/layer.2/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.3/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.3/attention/output/Add_output_0', '/model/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.3/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.3/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.3/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.3.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.3/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.3.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.3/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1453']\n",
      "['/model/bert/encoder/layer.3/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.3/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.3.intermediate.dense.bias', '/model/bert/encoder/layer.3/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.3/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.3/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.3/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.3/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1454']\n",
      "['/model/bert/encoder/layer.3/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.3/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.3.output.dense.bias', '/model/bert/encoder/layer.3/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.3/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.3/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.3/output/dense/Add_output_0', '/model/bert/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.3/output/Add_output_0']\n",
      "/model/bert/encoder/layer.3/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.3/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.3/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.3/output/Add_output_0', '/model/bert/encoder/layer.3/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.3/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.3/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.3/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.3/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.3/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.3/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.3/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.3/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.3/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.3/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.3/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.3.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.3/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.3.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1455']\n",
      "['/model/bert/encoder/layer.4/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.4.attention.self.query.bias', '/model/bert/encoder/layer.4/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1456']\n",
      "['/model/bert/encoder/layer.4/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.4.attention.self.key.bias', '/model/bert/encoder/layer.4/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.4/attention/self/key/Add_output_0', '/model/bert/encoder/layer.4/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1462']\n",
      "['/model/bert/encoder/layer.4/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.4.attention.self.value.bias', '/model/bert/encoder/layer.4/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.4/attention/self/value/Add_output_0', '/model/bert/encoder/layer.4/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.4/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.4/attention/self/query/Add_output_0', '/model/bert/encoder/layer.4/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.4/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.4/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.4/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.4/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.4/attention/self/MatMul_output_0', '/model/bert/encoder/layer.4/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.4/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.4/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.4/attention/self/Softmax_output_0', '/model/bert/encoder/layer.4/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.4/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.4/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.4/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.4/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.4/attention/self/Reshape_3_output_0', 'onnx::MatMul_1477']\n",
      "['/model/bert/encoder/layer.4/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.4.attention.output.dense.bias', '/model/bert/encoder/layer.4/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.4/attention/output/dense/Add_output_0', '/model/bert/encoder/layer.3/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.4/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.4/attention/output/Add_output_0', '/model/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.4/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.4/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.4/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.4.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.4/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.4.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.4/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1478']\n",
      "['/model/bert/encoder/layer.4/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.4/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.4.intermediate.dense.bias', '/model/bert/encoder/layer.4/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.4/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.4/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.4/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.4/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1479']\n",
      "['/model/bert/encoder/layer.4/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.4/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.4.output.dense.bias', '/model/bert/encoder/layer.4/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.4/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.4/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.4/output/dense/Add_output_0', '/model/bert/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.4/output/Add_output_0']\n",
      "/model/bert/encoder/layer.4/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.4/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.4/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.4/output/Add_output_0', '/model/bert/encoder/layer.4/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.4/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.4/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.4/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.4/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.4/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.4/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.4/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.4/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.4/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.4/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.4/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.4.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.4/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.4.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1480']\n",
      "['/model/bert/encoder/layer.5/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.5.attention.self.query.bias', '/model/bert/encoder/layer.5/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1481']\n",
      "['/model/bert/encoder/layer.5/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.5.attention.self.key.bias', '/model/bert/encoder/layer.5/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.5/attention/self/key/Add_output_0', '/model/bert/encoder/layer.5/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1487']\n",
      "['/model/bert/encoder/layer.5/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.5.attention.self.value.bias', '/model/bert/encoder/layer.5/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.5/attention/self/value/Add_output_0', '/model/bert/encoder/layer.5/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.5/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.5/attention/self/query/Add_output_0', '/model/bert/encoder/layer.5/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.5/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.5/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.5/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.5/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.5/attention/self/MatMul_output_0', '/model/bert/encoder/layer.5/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.5/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.5/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.5/attention/self/Softmax_output_0', '/model/bert/encoder/layer.5/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.5/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.5/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.5/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.5/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.5/attention/self/Reshape_3_output_0', 'onnx::MatMul_1502']\n",
      "['/model/bert/encoder/layer.5/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.5.attention.output.dense.bias', '/model/bert/encoder/layer.5/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.5/attention/output/dense/Add_output_0', '/model/bert/encoder/layer.4/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.5/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.5/attention/output/Add_output_0', '/model/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.5/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.5/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.5/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.5.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.5/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.5.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.5/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1503']\n",
      "['/model/bert/encoder/layer.5/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.5/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.5.intermediate.dense.bias', '/model/bert/encoder/layer.5/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.5/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.5/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.5/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.5/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1504']\n",
      "['/model/bert/encoder/layer.5/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.5/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.5.output.dense.bias', '/model/bert/encoder/layer.5/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.5/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.5/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.5/output/dense/Add_output_0', '/model/bert/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.5/output/Add_output_0']\n",
      "/model/bert/encoder/layer.5/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.5/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.5/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.5/output/Add_output_0', '/model/bert/encoder/layer.5/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.5/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.5/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.5/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.5/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.5/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.5/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.5/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.5/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.5/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.5/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.5/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.5.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.5/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.5.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1505']\n",
      "['/model/bert/encoder/layer.6/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.6.attention.self.query.bias', '/model/bert/encoder/layer.6/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1506']\n",
      "['/model/bert/encoder/layer.6/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.6.attention.self.key.bias', '/model/bert/encoder/layer.6/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.6/attention/self/key/Add_output_0', '/model/bert/encoder/layer.6/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.5/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1512']\n",
      "['/model/bert/encoder/layer.6/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.6.attention.self.value.bias', '/model/bert/encoder/layer.6/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.6/attention/self/value/Add_output_0', '/model/bert/encoder/layer.6/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.6/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.6/attention/self/query/Add_output_0', '/model/bert/encoder/layer.6/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.6/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.6/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.6/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.6/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.6/attention/self/MatMul_output_0', '/model/bert/encoder/layer.6/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.6/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.6/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.6/attention/self/Softmax_output_0', '/model/bert/encoder/layer.6/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.6/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.6/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.6/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.6/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.6/attention/self/Reshape_3_output_0', 'onnx::MatMul_1527']\n",
      "['/model/bert/encoder/layer.6/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.6.attention.output.dense.bias', '/model/bert/encoder/layer.6/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.6/attention/output/dense/Add_output_0', '/model/bert/encoder/layer.5/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.6/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.6/attention/output/Add_output_0', '/model/bert/encoder/layer.6/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.6/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.6/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.6/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.6.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.6/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.6.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.6/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1528']\n",
      "['/model/bert/encoder/layer.6/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.6/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.6.intermediate.dense.bias', '/model/bert/encoder/layer.6/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.6/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.6/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.6/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.6/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1529']\n",
      "['/model/bert/encoder/layer.6/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.6/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.6.output.dense.bias', '/model/bert/encoder/layer.6/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.6/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.6/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.6/output/dense/Add_output_0', '/model/bert/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.6/output/Add_output_0']\n",
      "/model/bert/encoder/layer.6/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.6/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.6/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.6/output/Add_output_0', '/model/bert/encoder/layer.6/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.6/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.6/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.6/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.6/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.6/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.6/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.6/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.6/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.6/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.6/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.6/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.6.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.6/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.6.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1530']\n",
      "['/model/bert/encoder/layer.7/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.7.attention.self.query.bias', '/model/bert/encoder/layer.7/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1531']\n",
      "['/model/bert/encoder/layer.7/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.7.attention.self.key.bias', '/model/bert/encoder/layer.7/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.7/attention/self/key/Add_output_0', '/model/bert/encoder/layer.7/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.6/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1537']\n",
      "['/model/bert/encoder/layer.7/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.7.attention.self.value.bias', '/model/bert/encoder/layer.7/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.7/attention/self/value/Add_output_0', '/model/bert/encoder/layer.7/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.7/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.7/attention/self/query/Add_output_0', '/model/bert/encoder/layer.7/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.7/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.7/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.7/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.7/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.7/attention/self/MatMul_output_0', '/model/bert/encoder/layer.7/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.7/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.7/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.7/attention/self/Softmax_output_0', '/model/bert/encoder/layer.7/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.7/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.7/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.7/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.7/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.7/attention/self/Reshape_3_output_0', 'onnx::MatMul_1552']\n",
      "['/model/bert/encoder/layer.7/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.7.attention.output.dense.bias', '/model/bert/encoder/layer.7/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.7/attention/output/dense/Add_output_0', '/model/bert/encoder/layer.6/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.7/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.7/attention/output/Add_output_0', '/model/bert/encoder/layer.7/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.7/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.7/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.7/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.7.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.7/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.7.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.7/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1553']\n",
      "['/model/bert/encoder/layer.7/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.7/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.7.intermediate.dense.bias', '/model/bert/encoder/layer.7/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.7/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.7/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.7/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.7/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1554']\n",
      "['/model/bert/encoder/layer.7/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.7/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.7.output.dense.bias', '/model/bert/encoder/layer.7/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.7/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.7/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.7/output/dense/Add_output_0', '/model/bert/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.7/output/Add_output_0']\n",
      "/model/bert/encoder/layer.7/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.7/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.7/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.7/output/Add_output_0', '/model/bert/encoder/layer.7/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.7/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.7/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.7/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.7/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.7/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.7/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.7/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.7/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.7/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.7/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.7/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.7.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.7/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.7.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1555']\n",
      "['/model/bert/encoder/layer.8/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.8.attention.self.query.bias', '/model/bert/encoder/layer.8/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1556']\n",
      "['/model/bert/encoder/layer.8/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.8.attention.self.key.bias', '/model/bert/encoder/layer.8/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.8/attention/self/key/Add_output_0', '/model/bert/encoder/layer.8/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.7/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1562']\n",
      "['/model/bert/encoder/layer.8/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.8.attention.self.value.bias', '/model/bert/encoder/layer.8/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.8/attention/self/value/Add_output_0', '/model/bert/encoder/layer.8/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.8/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.8/attention/self/query/Add_output_0', '/model/bert/encoder/layer.8/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.8/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.8/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.8/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.8/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.8/attention/self/MatMul_output_0', '/model/bert/encoder/layer.8/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.8/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.8/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.8/attention/self/Softmax_output_0', '/model/bert/encoder/layer.8/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.8/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.8/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.8/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.8/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.8/attention/self/Reshape_3_output_0', 'onnx::MatMul_1577']\n",
      "['/model/bert/encoder/layer.8/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.8.attention.output.dense.bias', '/model/bert/encoder/layer.8/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.8/attention/output/dense/Add_output_0', '/model/bert/encoder/layer.7/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.8/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.8/attention/output/Add_output_0', '/model/bert/encoder/layer.8/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.8/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.8/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.8/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.8.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.8/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.8.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.8/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1578']\n",
      "['/model/bert/encoder/layer.8/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.8/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.8.intermediate.dense.bias', '/model/bert/encoder/layer.8/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.8/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.8/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.8/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.8/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1579']\n",
      "['/model/bert/encoder/layer.8/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.8/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.8.output.dense.bias', '/model/bert/encoder/layer.8/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.8/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.8/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.8/output/dense/Add_output_0', '/model/bert/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.8/output/Add_output_0']\n",
      "/model/bert/encoder/layer.8/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.8/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.8/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.8/output/Add_output_0', '/model/bert/encoder/layer.8/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.8/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.8/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.8/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.8/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.8/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.8/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.8/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.8/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.8/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.8/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.8/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.8.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.8/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.8.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1580']\n",
      "['/model/bert/encoder/layer.9/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.9.attention.self.query.bias', '/model/bert/encoder/layer.9/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1581']\n",
      "['/model/bert/encoder/layer.9/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.9.attention.self.key.bias', '/model/bert/encoder/layer.9/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.9/attention/self/key/Add_output_0', '/model/bert/encoder/layer.9/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.8/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1587']\n",
      "['/model/bert/encoder/layer.9/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.9.attention.self.value.bias', '/model/bert/encoder/layer.9/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.9/attention/self/value/Add_output_0', '/model/bert/encoder/layer.9/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.9/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.9/attention/self/query/Add_output_0', '/model/bert/encoder/layer.9/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.9/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.9/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.9/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.9/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.9/attention/self/MatMul_output_0', '/model/bert/encoder/layer.9/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.9/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.9/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.9/attention/self/Softmax_output_0', '/model/bert/encoder/layer.9/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.9/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.9/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.9/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.9/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.9/attention/self/Reshape_3_output_0', 'onnx::MatMul_1602']\n",
      "['/model/bert/encoder/layer.9/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.9.attention.output.dense.bias', '/model/bert/encoder/layer.9/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.9/attention/output/dense/Add_output_0', '/model/bert/encoder/layer.8/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.9/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.9/attention/output/Add_output_0', '/model/bert/encoder/layer.9/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.9/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.9/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.9/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.9.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.9/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.9.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.9/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1603']\n",
      "['/model/bert/encoder/layer.9/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.9/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.9.intermediate.dense.bias', '/model/bert/encoder/layer.9/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.9/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.9/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.9/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.9/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1604']\n",
      "['/model/bert/encoder/layer.9/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.9/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.9.output.dense.bias', '/model/bert/encoder/layer.9/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.9/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.9/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.9/output/dense/Add_output_0', '/model/bert/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.9/output/Add_output_0']\n",
      "/model/bert/encoder/layer.9/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.9/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.9/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.9/output/Add_output_0', '/model/bert/encoder/layer.9/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.9/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.9/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.9/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.9/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.9/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.9/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.9/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.9/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.9/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.9/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.9/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.9.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.9/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.9.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1605']\n",
      "['/model/bert/encoder/layer.10/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.10.attention.self.query.bias', '/model/bert/encoder/layer.10/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1606']\n",
      "['/model/bert/encoder/layer.10/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.10.attention.self.key.bias', '/model/bert/encoder/layer.10/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.10/attention/self/key/Add_output_0', '/model/bert/encoder/layer.10/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.9/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1612']\n",
      "['/model/bert/encoder/layer.10/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.10.attention.self.value.bias', '/model/bert/encoder/layer.10/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.10/attention/self/value/Add_output_0', '/model/bert/encoder/layer.10/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.10/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.10/attention/self/query/Add_output_0', '/model/bert/encoder/layer.10/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.10/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.10/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.10/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.10/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.10/attention/self/MatMul_output_0', '/model/bert/encoder/layer.10/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.10/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.10/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.10/attention/self/Softmax_output_0', '/model/bert/encoder/layer.10/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.10/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.10/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.10/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.10/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.10/attention/self/Reshape_3_output_0', 'onnx::MatMul_1627']\n",
      "['/model/bert/encoder/layer.10/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.10.attention.output.dense.bias', '/model/bert/encoder/layer.10/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.10/attention/output/dense/Add_output_0', '/model/bert/encoder/layer.9/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.10/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.10/attention/output/Add_output_0', '/model/bert/encoder/layer.10/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.10/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.10/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.10/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.10.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.10/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.10.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.10/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1628']\n",
      "['/model/bert/encoder/layer.10/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.10/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.10.intermediate.dense.bias', '/model/bert/encoder/layer.10/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.10/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.10/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.10/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.10/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1629']\n",
      "['/model/bert/encoder/layer.10/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.10/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.10.output.dense.bias', '/model/bert/encoder/layer.10/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.10/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.10/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.10/output/dense/Add_output_0', '/model/bert/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.10/output/Add_output_0']\n",
      "/model/bert/encoder/layer.10/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.10/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.10/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.10/output/Add_output_0', '/model/bert/encoder/layer.10/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.10/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.10/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.10/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.10/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.10/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.10/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.10/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.10/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.10/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.10/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.10/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.10.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.10/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.10.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/query/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1630']\n",
      "['/model/bert/encoder/layer.11/attention/self/query/MatMul_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/query/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.11.attention.self.query.bias', '/model/bert/encoder/layer.11/attention/self/query/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/query/Add_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/key/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1631']\n",
      "['/model/bert/encoder/layer.11/attention/self/key/MatMul_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/key/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.11.attention.self.key.bias', '/model/bert/encoder/layer.11/attention/self/key/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/key/Add_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/attention/self/Constant_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Reshape\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.11/attention/self/key/Add_output_0', '/model/bert/encoder/layer.11/attention/self/Constant_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/Reshape_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/value/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.10/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1637']\n",
      "['/model/bert/encoder/layer.11/attention/self/value/MatMul_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/value/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.11.attention.self.value.bias', '/model/bert/encoder/layer.11/attention/self/value/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/value/Add_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/attention/self/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Reshape_1\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.11/attention/self/value/Add_output_0', '/model/bert/encoder/layer.11/attention/self/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/Reshape_1_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Transpose\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.11/attention/self/Reshape_1_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/Transpose_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/attention/self/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Reshape_2\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.11/attention/self/query/Add_output_0', '/model/bert/encoder/layer.11/attention/self/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/Reshape_2_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Transpose_1\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.11/attention/self/Reshape_2_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/Transpose_1_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Transpose_2\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.11/attention/self/Reshape_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/Transpose_2_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.11/attention/self/Transpose_1_output_0', '/model/bert/encoder/layer.11/attention/self/Transpose_2_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/MatMul_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Constant_3\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/attention/self/Constant_3_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.11/attention/self/MatMul_output_0', '/model/bert/encoder/layer.11/attention/self/Constant_3_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/Div_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.11/attention/self/Div_output_0', '/model/bert/Mul_1_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/Add_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Softmax\n",
      "Softmax\n",
      "['/model/bert/encoder/layer.11/attention/self/Add_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/Softmax_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/MatMul_1\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.11/attention/self/Softmax_output_0', '/model/bert/encoder/layer.11/attention/self/Transpose_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/MatMul_1_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Transpose_3\n",
      "Transpose\n",
      "['/model/bert/encoder/layer.11/attention/self/MatMul_1_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/Transpose_3_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Constant_4\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/attention/self/Constant_4_output_0']\n",
      "/model/bert/encoder/layer.11/attention/self/Reshape_3\n",
      "Reshape\n",
      "['/model/bert/encoder/layer.11/attention/self/Transpose_3_output_0', '/model/bert/encoder/layer.11/attention/self/Constant_4_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/self/Reshape_3_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.11/attention/self/Reshape_3_output_0', 'onnx::MatMul_1652']\n",
      "['/model/bert/encoder/layer.11/attention/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.11.attention.output.dense.bias', '/model/bert/encoder/layer.11/attention/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.11/attention/output/dense/Add_output_0', '/model/bert/encoder/layer.10/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/output/Add_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.11/attention/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.11/attention/output/Add_output_0', '/model/bert/encoder/layer.11/attention/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.11/attention/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.11/attention/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.11/attention/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.11.attention.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.11/attention/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.11.attention.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/encoder/layer.11/intermediate/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0', 'onnx::MatMul_1653']\n",
      "['/model/bert/encoder/layer.11/intermediate/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.11/intermediate/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.11.intermediate.dense.bias', '/model/bert/encoder/layer.11/intermediate/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.11/intermediate/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.11/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Constant_output_0']\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Div_output_0']\n",
      "/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Erf\n",
      "Erf\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Div_output_0']\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Erf_output_0']\n",
      "/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Erf_output_0', '/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Add_output_0']\n",
      "/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.11/intermediate/dense/Add_output_0', '/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Add_output_0']\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Mul_output_0']\n",
      "/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Constant_2\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1\n",
      "Mul\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Mul_output_0', '/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Constant_2_output_0']\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0']\n",
      "/model/bert/encoder/layer.11/output/dense/MatMul\n",
      "MatMul\n",
      "['/model/bert/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0', 'onnx::MatMul_1654']\n",
      "['/model/bert/encoder/layer.11/output/dense/MatMul_output_0']\n",
      "/model/bert/encoder/layer.11/output/dense/Add\n",
      "Add\n",
      "['model.bert.encoder.layer.11.output.dense.bias', '/model/bert/encoder/layer.11/output/dense/MatMul_output_0']\n",
      "['/model/bert/encoder/layer.11/output/dense/Add_output_0']\n",
      "/model/bert/encoder/layer.11/output/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.11/output/dense/Add_output_0', '/model/bert/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0']\n",
      "['/model/bert/encoder/layer.11/output/Add_output_0']\n",
      "/model/bert/encoder/layer.11/output/LayerNorm/ReduceMean\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.11/output/Add_output_0']\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/ReduceMean_output_0']\n",
      "/model/bert/encoder/layer.11/output/LayerNorm/Sub\n",
      "Sub\n",
      "['/model/bert/encoder/layer.11/output/Add_output_0', '/model/bert/encoder/layer.11/output/LayerNorm/ReduceMean_output_0']\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Sub_output_0']\n",
      "/model/bert/encoder/layer.11/output/LayerNorm/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Constant_output_0']\n",
      "/model/bert/encoder/layer.11/output/LayerNorm/Pow\n",
      "Pow\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.11/output/LayerNorm/Constant_output_0']\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Pow_output_0']\n",
      "/model/bert/encoder/layer.11/output/LayerNorm/ReduceMean_1\n",
      "ReduceMean\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Pow_output_0']\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0']\n",
      "/model/bert/encoder/layer.11/output/LayerNorm/Constant_1\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Constant_1_output_0']\n",
      "/model/bert/encoder/layer.11/output/LayerNorm/Add\n",
      "Add\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/ReduceMean_1_output_0', '/model/bert/encoder/layer.11/output/LayerNorm/Constant_1_output_0']\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Add_output_0']\n",
      "/model/bert/encoder/layer.11/output/LayerNorm/Sqrt\n",
      "Sqrt\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Add_output_0']\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Sqrt_output_0']\n",
      "/model/bert/encoder/layer.11/output/LayerNorm/Div\n",
      "Div\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Sub_output_0', '/model/bert/encoder/layer.11/output/LayerNorm/Sqrt_output_0']\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Div_output_0']\n",
      "/model/bert/encoder/layer.11/output/LayerNorm/Mul\n",
      "Mul\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Div_output_0', 'model.bert.encoder.layer.11.output.LayerNorm.weight']\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Mul_output_0']\n",
      "/model/bert/encoder/layer.11/output/LayerNorm/Add_1\n",
      "Add\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Mul_output_0', 'model.bert.encoder.layer.11.output.LayerNorm.bias']\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Add_1_output_0']\n",
      "/model/bert/pooler/Constant\n",
      "Constant\n",
      "[]\n",
      "['/model/bert/pooler/Constant_output_0']\n",
      "/model/bert/pooler/Gather\n",
      "Gather\n",
      "['/model/bert/encoder/layer.11/output/LayerNorm/Add_1_output_0', '/model/bert/pooler/Constant_output_0']\n",
      "['/model/bert/pooler/Gather_output_0']\n",
      "/model/bert/pooler/dense/Gemm\n",
      "Gemm\n",
      "['/model/bert/pooler/Gather_output_0', 'model.bert.pooler.dense.weight', 'model.bert.pooler.dense.bias']\n",
      "['/model/bert/pooler/dense/Gemm_output_0']\n",
      "/model/bert/pooler/activation/Tanh\n",
      "Tanh\n",
      "['/model/bert/pooler/dense/Gemm_output_0']\n",
      "['/model/bert/pooler/activation/Tanh_output_0']\n",
      "/model/linear/Gemm\n",
      "Gemm\n",
      "['/model/bert/pooler/activation/Tanh_output_0', 'model.linear.weight', 'model.linear.bias']\n",
      "['/model/linear/Gemm_output_0']\n",
      "/model/relu/Relu\n",
      "Relu\n",
      "['/model/linear/Gemm_output_0']\n",
      "['/model/relu/Relu_output_0']\n",
      "/softmax/Softmax\n",
      "Softmax\n",
      "['/model/relu/Relu_output_0']\n",
      "['probs']\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(onnxfile)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "graph_def = onnx_model.graph\n",
    "\n",
    "nodes = graph_def.node\n",
    "\n",
    "for node in nodes:\n",
    "        print(node.name)\n",
    "        print(node.op_type)\n",
    "        print(node.input)\n",
    "        print(node.output)\n",
    "        # # Modify batchnorm attributes.\n",
    "        # if node.op_type == \"BatchNormalization\":\n",
    "        #     print(\"Attributes before adding:\")\n",
    "        #     for attribute in node.attribute:\n",
    "        #         print(attribute)\n",
    "        #     # Add epislon for the BN nodes.\n",
    "        #     epsilon_attribute = onnx.helper.make_attribute(\"epsilon\", 1e-06)\n",
    "        #     node.attribute.extend([epsilon_attribute])\n",
    "        #     # node.attribute.pop() # Pop an attribute if necessary.\n",
    "        #     print(\"Attributes after adding:\")\n",
    "        #     for attribute in node.attribute:\n",
    "        #         print(attribute)\n",
    "\n",
    "\n",
    "# # n1 = [n for n in graph.node if n.output == ['probs']][0]\n",
    "# # print(n)\n",
    "\n",
    "# output = graph.output\n",
    "\n",
    "new_node = onnx.helper.make_node(\n",
    "    'LabelEncoder',\n",
    "    inputs=['probs'],\n",
    "    outputs=['Y'],\n",
    "    keys_strings=labels.keys(),\n",
    "    values_int64s=labels.values()\n",
    ")\n",
    "\n",
    "# X = onnx.helper.make_tensor_value_info(\"X\", onnx.TensorProto.STRING, [None])\n",
    "# Y = onnx.helper.make_tensor_value_info(\"Y\", onnx.TensorProto.INT64, [None])\n",
    "\n",
    "# # idx = output.index\n",
    "# # print(idx)\n",
    "\n",
    "# # graph.node.remove(output)\n",
    "# graph.node.append(new_node)\n",
    "# # graph.node.index(idx, new_node)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# onnx.checker.check_model(onnx_model)\n",
    "# onnx.save(onnx_model, modified_onnxfile)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(graph)\n",
    "\n",
    "# pads = onnx.helper.make_tensor('avg_pads', onnx.TensorProto.INT64, [8], np.zeros(8, dtype=int))\n",
    "# graph.initializer.append(pads)\n",
    "# node = graph.node[584]\n",
    "# new_node = onnx.helper.make_node(\n",
    "#     'Pad',\n",
    "#     name='__Pad_584_fixed',\n",
    "#     inputs=['675', 'avg_pads'],\n",
    "#     outputs=['676'],\n",
    "#     mode='constant'\n",
    "# )\n",
    "# graph.node.remove(node)\n",
    "# graph.node.insert(584, new_node)\n",
    "# # Fix Equals (replace with Not)\n",
    "# node = graph.node[322]\n",
    "# new_node = onnx.helper.make_node(\n",
    "#     'Not',\n",
    "#     name='__Not__Equal_322',\n",
    "#     inputs=['412'],\n",
    "#     outputs=['414'],\n",
    "# )\n",
    "# graph.node.remove(node)\n",
    "# graph.node.insert(322, new_node)\n",
    "\n",
    "# onnx.checker.check_model(onnx_model)\n",
    "# onnx.save(onnx_model, onnxfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44adc98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([6], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "# amap = {str(i): i for i in range(20)}\n",
    "n = onnx.helper.make_node(\n",
    "    'LabelEncoder',\n",
    "    inputs=['X'],\n",
    "    outputs=['Y'],\n",
    "    keys_strings=labels.keys(),\n",
    "    # values_int64s=labels.values(), \n",
    "    values_int64s=labels.values(), \n",
    "    domain='ai.onnx.ml'\n",
    ")\n",
    "\n",
    "X = onnx.helper.make_tensor_value_info(\"X\", onnx.TensorProto.STRING, [None])\n",
    "Y = onnx.helper.make_tensor_value_info(\"Y\", onnx.TensorProto.INT64, [None])\n",
    "\n",
    "graph_def = onnx.helper.make_graph(\n",
    "    nodes=[n],\n",
    "    name=\"mapper\",\n",
    "    inputs=[X],\n",
    "    outputs=[Y]\n",
    ")\n",
    "\n",
    "modelX = onnx.helper.make_model(\n",
    "    graph_def,\n",
    "    opset_imports=[\n",
    "        onnx.helper.make_opsetid('ai.onnx.ml', 2), \n",
    "        onnx.helper.make_opsetid('', 14)],\n",
    ")\n",
    "\n",
    "out_path = \"modified_model.onnx\"\n",
    "onnx.checker.check_model(modelX)\n",
    "onnx.save(modelX, out_path)\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(out_path)\n",
    "inp = np.array([\"AskIfSell\"])\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: inp}\n",
    "print(ort_session.run(None, ort_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "602244b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240fd3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"input_ids\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 7\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 512\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"mask\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 7\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 512\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n",
      "[name: \"sorted_probs\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 20\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx import numpy_helper\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "onnx_model = onnx.load(onnxfile)\n",
    "\n",
    "graph = onnx_model.graph\n",
    "# initalizers = dict()\n",
    "# for init in graph.initializer:\n",
    "#     initalizers[init.name] = numpy_helper.to_array(init)\n",
    "\n",
    "print(graph.input)\n",
    "print(graph.output)\n",
    "# for name, p in model2.named_parameters():\n",
    "#     p.data = (torch.from_numpy(initalizers[name])).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da87e699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "52eb70b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxruntime in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (1.14.1)\n",
      "Requirement already satisfied: protobuf in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: coloredlogs in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime) (1.23.5)\n",
      "Requirement already satisfied: packaging in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime) (23.0)\n",
      "Requirement already satisfied: flatbuffers in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime) (23.3.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: transformers[onnx] in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (4.27.1)\n",
      "Requirement already satisfied: filelock in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers[onnx]) (3.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers[onnx]) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers[onnx]) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers[onnx]) (0.13.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers[onnx]) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers[onnx]) (2022.10.31)\n",
      "Requirement already satisfied: requests in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers[onnx]) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers[onnx]) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers[onnx]) (23.0)\n",
      "Collecting onnxruntime-tools>=1.4.2\n",
      "  Downloading onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: onnxruntime>=1.4.0 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from transformers[onnx]) (1.14.1)\n",
      "Collecting onnxconverter-common\n",
      "  Downloading onnxconverter_common-1.13.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tf2onnx\n",
      "  Downloading tf2onnx-1.14.0-py3-none-any.whl (451 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.2/451.2 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers[onnx]) (4.5.0)\n",
      "Requirement already satisfied: coloredlogs in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime>=1.4.0->transformers[onnx]) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime>=1.4.0->transformers[onnx]) (1.11.1)\n",
      "Requirement already satisfied: protobuf in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime>=1.4.0->transformers[onnx]) (3.20.3)\n",
      "Requirement already satisfied: flatbuffers in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime>=1.4.0->transformers[onnx]) (23.3.3)\n",
      "Requirement already satisfied: onnx in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (1.13.1)\n",
      "Requirement already satisfied: py-cpuinfo in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (9.0.0)\n",
      "Collecting py3nvml\n",
      "  Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]) (5.9.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from requests->transformers[onnx]) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from requests->transformers[onnx]) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from requests->transformers[onnx]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from requests->transformers[onnx]) (1.26.15)\n",
      "Requirement already satisfied: six in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from tf2onnx->transformers[onnx]) (1.16.0)\n",
      "Collecting flatbuffers\n",
      "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.4.0->transformers[onnx]) (10.0)\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages (from sympy->onnxruntime>=1.4.0->transformers[onnx]) (1.3.0)\n",
      "Installing collected packages: flatbuffers, xmltodict, tf2onnx, py3nvml, onnxconverter-common, onnxruntime-tools\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 23.3.3\n",
      "    Uninstalling flatbuffers-23.3.3:\n",
      "      Successfully uninstalled flatbuffers-23.3.3\n",
      "Successfully installed flatbuffers-2.0.7 onnxconverter-common-1.13.0 onnxruntime-tools-1.7.0 py3nvml-0.2.7 tf2onnx-1.14.0 xmltodict-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime\n",
    "!pip install transformers[onnx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "16631c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Framework not requested. Using torch to export to ONNX.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using framework PyTorch: 2.0.0+cu117\n",
      "/home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:223: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Validating ONNX model...\n",
      "\t-[✓] ONNX model output names match reference model ({'last_hidden_state'})\n",
      "\t- Validating ONNX Model output \"last_hidden_state\":\n",
      "\t\t-[✓] (3, 9, 768) matches (3, 9, 768)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "All good, model saved at: onnx/model.onnx\n",
      "/home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages/transformers/onnx/__main__.py:178: FutureWarning: The export was done by transformers.onnx which is deprecated and will be removed in v5. We recommend using optimum.exporters.onnx in future. You can find more information here: https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/export_a_model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!python -m transformers.onnx --model=distilbert-base-uncased onnx/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "25a0c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "from transformers import AutoTokenizer\n",
    "from onnxruntime import InferenceSession\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "session = InferenceSession(\"onnx/model.onnx\")\n",
    "# ONNX Runtime expects NumPy arrays as input\n",
    "inputs = tokenizer(\"Using DistilBERT with ONNX Runtime!\", return_tensors=\"np\")\n",
    "outputs = session.run(output_names=[\"last_hidden_state\"], input_feed=dict(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b5301271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfsservices/miniconda3/envs/nlp_test/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:717: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2023482/1516756600.py:21: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  probs = {ids_to_labels[i]:prob for i, prob in enumerate(torch.softmax(output[0], dim=-1).cpu().numpy())}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: numpy.float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# model_2_export = torch.jit.script(model2)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m x \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDo you have this equipment?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mexport(model2,                    \u001b[39m# model being run\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m                   x,                         \u001b[39m# model input (or a tuple for multiple inputs)\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m                   \u001b[39m\"\u001b[39;49m\u001b[39mintent_classifier.onnx\u001b[39;49m\u001b[39m\"\u001b[39;49m,   \u001b[39m# where to save the model (can be a file or file-like object)\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m                   export_params\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,        \u001b[39m# store the trained parameter weights inside the model file\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m                   opset_version\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,          \u001b[39m# the ONNX version to export the model to\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m                   do_constant_folding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,  \u001b[39m# whether to execute constant folding for optimization\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m                   input_names \u001b[39m=\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m],   \u001b[39m# the model's input names\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m                   output_names \u001b[39m=\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39mintents\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m# the model's output names\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m                   dynamic_axes\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m : {\u001b[39m0\u001b[39;49m : \u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m},    \u001b[39m# variable length axes\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mintents\u001b[39;49m\u001b[39m'\u001b[39;49m : {\u001b[39m0\u001b[39;49m : \u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m}})\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_test/lib/python3.10/site-packages/torch/onnx/utils.py:506\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39m@_beartype\u001b[39m\u001b[39m.\u001b[39mbeartype\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[1;32m    190\u001b[0m     model: Union[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     export_modules_as_functions: Union[\u001b[39mbool\u001b[39m, Collection[Type[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule]]] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    207\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[39m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m     _export(\n\u001b[1;32m    507\u001b[0m         model,\n\u001b[1;32m    508\u001b[0m         args,\n\u001b[1;32m    509\u001b[0m         f,\n\u001b[1;32m    510\u001b[0m         export_params,\n\u001b[1;32m    511\u001b[0m         verbose,\n\u001b[1;32m    512\u001b[0m         training,\n\u001b[1;32m    513\u001b[0m         input_names,\n\u001b[1;32m    514\u001b[0m         output_names,\n\u001b[1;32m    515\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type,\n\u001b[1;32m    516\u001b[0m         opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[1;32m    517\u001b[0m         do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[1;32m    518\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m    519\u001b[0m         keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[1;32m    520\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets,\n\u001b[1;32m    521\u001b[0m         export_modules_as_functions\u001b[39m=\u001b[39;49mexport_modules_as_functions,\n\u001b[1;32m    522\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_test/lib/python3.10/site-packages/torch/onnx/utils.py:1548\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1545\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1546\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1548\u001b[0m graph, params_dict, torch_out \u001b[39m=\u001b[39m _model_to_graph(\n\u001b[1;32m   1549\u001b[0m     model,\n\u001b[1;32m   1550\u001b[0m     args,\n\u001b[1;32m   1551\u001b[0m     verbose,\n\u001b[1;32m   1552\u001b[0m     input_names,\n\u001b[1;32m   1553\u001b[0m     output_names,\n\u001b[1;32m   1554\u001b[0m     operator_export_type,\n\u001b[1;32m   1555\u001b[0m     val_do_constant_folding,\n\u001b[1;32m   1556\u001b[0m     fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1557\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   1558\u001b[0m     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1559\u001b[0m )\n\u001b[1;32m   1561\u001b[0m \u001b[39m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m defer_weight_export \u001b[39m=\u001b[39m (\n\u001b[1;32m   1563\u001b[0m     export_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _exporter_states\u001b[39m.\u001b[39mExportTypes\u001b[39m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1564\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_test/lib/python3.10/site-packages/torch/onnx/utils.py:1113\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     args \u001b[39m=\u001b[39m (args,)\n\u001b[1;32m   1112\u001b[0m model \u001b[39m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1113\u001b[0m graph, params, torch_out, module \u001b[39m=\u001b[39m _create_jit_graph(model, args)\n\u001b[1;32m   1114\u001b[0m params_dict \u001b[39m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1116\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_test/lib/python3.10/site-packages/torch/onnx/utils.py:989\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    984\u001b[0m     graph \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m    985\u001b[0m         graph, flattened_args, param_count_list, \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    986\u001b[0m     )\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m graph, params, torch_out, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m graph, torch_out \u001b[39m=\u001b[39m _trace_and_get_graph_from_model(model, args)\n\u001b[1;32m    990\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    991\u001b[0m state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_test/lib/python3.10/site-packages/torch/onnx/utils.py:893\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    891\u001b[0m prev_autocast_cache_enabled \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    892\u001b[0m torch\u001b[39m.\u001b[39mset_autocast_cache_enabled(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 893\u001b[0m trace_graph, torch_out, inputs_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_get_trace_graph(\n\u001b[1;32m    894\u001b[0m     model,\n\u001b[1;32m    895\u001b[0m     args,\n\u001b[1;32m    896\u001b[0m     strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    897\u001b[0m     _force_outplace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    898\u001b[0m     _return_inputs_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    899\u001b[0m )\n\u001b[1;32m    900\u001b[0m torch\u001b[39m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    902\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_test/lib/python3.10/site-packages/torch/jit/_trace.py:1268\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(args, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m   1267\u001b[0m     args \u001b[39m=\u001b[39m (args,)\n\u001b[0;32m-> 1268\u001b[0m outs \u001b[39m=\u001b[39m ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1269\u001b[0m \u001b[39mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_test/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_test/lib/python3.10/site-packages/torch/jit/_trace.py:127\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(out_vars)\n\u001b[0;32m--> 127\u001b[0m graph, out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_create_graph_by_tracing(\n\u001b[1;32m    128\u001b[0m     wrapper,\n\u001b[1;32m    129\u001b[0m     in_vars \u001b[39m+\u001b[39;49m module_state,\n\u001b[1;32m    130\u001b[0m     _create_interpreter_name_lookup_fn(),\n\u001b[1;32m    131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrict,\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_force_outplace,\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs:\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m graph, outs[\u001b[39m0\u001b[39m], ret_inputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_test/lib/python3.10/site-packages/torch/jit/_trace.py:121\u001b[0m, in \u001b[0;36mONNXTracedModule.forward.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    120\u001b[0m     inputs_states[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m (inputs_states[\u001b[39m0\u001b[39m], trace_inputs)\n\u001b[0;32m--> 121\u001b[0m out_vars, _ \u001b[39m=\u001b[39m _flatten(outs)\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out_vars) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    123\u001b[0m     \u001b[39mreturn\u001b[39;00m out_vars[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: numpy.float32"
     ]
    }
   ],
   "source": [
    "# import torch.onnx\n",
    "\n",
    "# # model_2_export = torch.jit.script(model2)\n",
    "# # x = torch.as_tensor(\"Do you have this equipment?\")\n",
    "\n",
    "\n",
    "# torch.onnx.export(model2,                    # model being run\n",
    "#                   x,                         # model input (or a tuple for multiple inputs)\n",
    "#                   \"intent_classifier.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "#                   export_params=True,        # store the trained parameter weights inside the model file\n",
    "#                   opset_version=10,          # the ONNX version to export the model to\n",
    "#                   do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "#                   input_names = ['text'],   # the model's input names\n",
    "#                   output_names = ['intents'], # the model's output names\n",
    "#                   dynamic_axes={'text' : {0 : 'batch_size'},    # variable length axes\n",
    "#                                 'intents' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02871b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad8e6712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AskIfHaveEquipment': 0.7155939, 'AskIfBuy': 0.035149023, 'AskForEquipmentInstallation': 0.033871528, 'AskForInterest': 0.026417904, 'DoNotHaveEquipment': 0.02605449, 'AskIfSell': 0.021407254, 'HaveEquipment': 0.013339684, 'Decline': 0.012962977, 'None': 0.012009604, 'HaveDeinstalledEquipment': 0.011084783, 'AskForPrice': 0.009670952, 'DeclinePrice': 0.00965968, 'Accept': 0.009097273, 'DeclineToBuy': 0.009097273, 'DeclineToSell': 0.009097273, 'HaveInstalledEquipment': 0.009097273, 'OfferPrice': 0.009097273, 'WantDeal': 0.009097273, 'WantToBuy': 0.009097273, 'WantToSell': 0.009097273}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"Do you have this equipment?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3567415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WantToBuy': 0.77064633, 'WantToSell': 0.046400234, 'WantDeal': 0.027831074, 'DeclineToBuy': 0.019905794, 'DeclinePrice': 0.013577436, 'HaveInstalledEquipment': 0.0113623245, 'Accept': 0.0094270315, 'AskIfBuy': 0.009304696, 'AskIfSell': 0.008376279, 'OfferPrice': 0.007767368, 'AskForEquipmentInstallation': 0.0075401287, 'AskForInterest': 0.0075401287, 'AskForPrice': 0.0075401287, 'AskIfHaveEquipment': 0.0075401287, 'Decline': 0.0075401287, 'DeclineToSell': 0.0075401287, 'DoNotHaveEquipment': 0.0075401287, 'HaveDeinstalledEquipment': 0.0075401287, 'HaveEquipment': 0.0075401287, 'None': 0.0075401287}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"I am going to buy it for my company.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aa806a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 0.97736883, 'AskForInterest': 0.0034101568, 'AskForPrice': 0.0022474593, 'AskIfHaveEquipment': 0.0018970915, 'Accept': 0.0016547564, 'WantDeal': 0.0012490745, 'AskForEquipmentInstallation': 0.001088749, 'Decline': 0.0010231821, 'AskIfBuy': 0.00086614804, 'AskIfSell': 0.000835869, 'DeclinePrice': 0.000835869, 'DeclineToBuy': 0.000835869, 'DeclineToSell': 0.000835869, 'DoNotHaveEquipment': 0.000835869, 'HaveDeinstalledEquipment': 0.000835869, 'HaveEquipment': 0.000835869, 'HaveInstalledEquipment': 0.000835869, 'OfferPrice': 0.000835869, 'WantToBuy': 0.000835869, 'WantToSell': 0.000835869}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"What is the whether today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7df3c690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AskForPrice': 0.9126778, 'AskForInterest': 0.02042869, 'AskIfBuy': 0.011594796, 'AskIfSell': 0.0052341246, 'Accept': 0.005062612, 'None': 0.0044942964, 'AskIfHaveEquipment': 0.0038659936, 'WantDeal': 0.0031420202, 'OfferPrice': 0.002811082, 'AskForEquipmentInstallation': 0.0027898855, 'Decline': 0.0027898855, 'DeclinePrice': 0.0027898855, 'DeclineToBuy': 0.0027898855, 'DeclineToSell': 0.0027898855, 'DoNotHaveEquipment': 0.0027898855, 'HaveDeinstalledEquipment': 0.0027898855, 'HaveEquipment': 0.0027898855, 'HaveInstalledEquipment': 0.0027898855, 'WantToBuy': 0.0027898855, 'WantToSell': 0.0027898855}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"price?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fecd3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 0.46456534, 'AskForInterest': 0.3589044, 'WantDeal': 0.02085898, 'Accept': 0.016223133, 'AskForPrice': 0.014868883, 'AskIfBuy': 0.014588483, 'AskForEquipmentInstallation': 0.011593876, 'AskIfHaveEquipment': 0.0115301665, 'HaveEquipment': 0.008184502, 'AskIfSell': 0.0075092996, 'WantToSell': 0.007505899, 'Decline': 0.0070741177, 'DeclinePrice': 0.0070741177, 'DeclineToBuy': 0.0070741177, 'DeclineToSell': 0.0070741177, 'DoNotHaveEquipment': 0.0070741177, 'HaveDeinstalledEquipment': 0.0070741177, 'HaveInstalledEquipment': 0.0070741177, 'OfferPrice': 0.0070741177, 'WantToBuy': 0.0070741177}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"good enough?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "096ea2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AskIfSell': 0.21709855, 'AskForEquipmentInstallation': 0.21300681, 'AskIfHaveEquipment': 0.13903241, 'AskForInterest': 0.101318724, 'AskIfBuy': 0.06915638, 'AskForPrice': 0.048866913, 'OfferPrice': 0.030460024, 'HaveDeinstalledEquipment': 0.021107292, 'WantToSell': 0.0165179, 'Accept': 0.013039547, 'Decline': 0.013039547, 'DeclinePrice': 0.013039547, 'DeclineToBuy': 0.013039547, 'DeclineToSell': 0.013039547, 'DoNotHaveEquipment': 0.013039547, 'HaveEquipment': 0.013039547, 'HaveInstalledEquipment': 0.013039547, 'None': 0.013039547, 'WantDeal': 0.013039547, 'WantToBuy': 0.013039547}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"kla tencor?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bf724f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WantToSell': 0.3074497, 'HaveEquipment': 0.14781605, 'WantToBuy': 0.073141046, 'DeclineToSell': 0.058000557, 'OfferPrice': 0.04403818, 'DeclinePrice': 0.04151325, 'Accept': 0.035329748, 'AskIfSell': 0.03185199, 'DoNotHaveEquipment': 0.031572387, 'None': 0.03013954, 'HaveInstalledEquipment': 0.02894686, 'AskForEquipmentInstallation': 0.018911198, 'AskForInterest': 0.018911198, 'AskForPrice': 0.018911198, 'AskIfBuy': 0.018911198, 'AskIfHaveEquipment': 0.018911198, 'Decline': 0.018911198, 'DeclineToBuy': 0.018911198, 'HaveDeinstalledEquipment': 0.018911198, 'WantDeal': 0.018911198}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"kla tencor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1bc9bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 0.9052222, 'AskForInterest': 0.0313498, 'Decline': 0.006507385, 'AskForEquipmentInstallation': 0.0063748485, 'AskIfHaveEquipment': 0.0056049842, 'WantDeal': 0.005475396, 'AskForPrice': 0.004673873, 'DeclineToBuy': 0.0038081172, 'Accept': 0.0025819542, 'AskIfBuy': 0.0025819542, 'AskIfSell': 0.0025819542, 'DeclinePrice': 0.0025819542, 'DeclineToSell': 0.0025819542, 'DoNotHaveEquipment': 0.0025819542, 'HaveDeinstalledEquipment': 0.0025819542, 'HaveEquipment': 0.0025819542, 'HaveInstalledEquipment': 0.0025819542, 'OfferPrice': 0.0025819542, 'WantToBuy': 0.0025819542, 'WantToSell': 0.0025819542}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"do it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c17a58ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AskForEquipmentInstallation': 0.7826641, 'AskIfSell': 0.03436578, 'AskIfHaveEquipment': 0.024888279, 'DeclineToSell': 0.014696896, 'AskIfBuy': 0.013911255, 'HaveDeinstalledEquipment': 0.013652937, 'AskForInterest': 0.00913006, 'OfferPrice': 0.009072743, 'HaveEquipment': 0.008787502, 'None': 0.008513548, 'Accept': 0.008031688, 'AskForPrice': 0.008031688, 'Decline': 0.008031688, 'DeclinePrice': 0.008031688, 'DeclineToBuy': 0.008031688, 'DoNotHaveEquipment': 0.008031688, 'HaveInstalledEquipment': 0.008031688, 'WantDeal': 0.008031688, 'WantToBuy': 0.008031688, 'WantToSell': 0.008031688}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"is it still deinstalled?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86c260f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HaveDeinstalledEquipment': 0.3117689, 'HaveInstalledEquipment': 0.09889904, 'HaveEquipment': 0.08805725, 'DeclineToSell': 0.0652029, 'WantToSell': 0.05262022, 'DeclineToBuy': 0.046810664, 'DoNotHaveEquipment': 0.038615946, 'WantToBuy': 0.029944621, 'OfferPrice': 0.02820212, 'None': 0.024586426, 'Accept': 0.0215292, 'AskForEquipmentInstallation': 0.0215292, 'AskForInterest': 0.0215292, 'AskForPrice': 0.0215292, 'AskIfBuy': 0.0215292, 'AskIfHaveEquipment': 0.0215292, 'AskIfSell': 0.0215292, 'Decline': 0.0215292, 'DeclinePrice': 0.0215292, 'WantDeal': 0.0215292}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"we are going to remove this unit from production next week.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7846e74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 0.9880149, 'WantDeal': 0.0016548098, 'Decline': 0.0015076428, 'Accept': 0.0013216882, 'AskForInterest': 0.0009711102, 'DeclineToBuy': 0.00086875685, 'DoNotHaveEquipment': 0.0006758194, 'AskIfHaveEquipment': 0.0004148142, 'AskForPrice': 0.00040727423, 'AskForEquipmentInstallation': 0.00037848423, 'AskIfBuy': 0.00037848423, 'AskIfSell': 0.00037848423, 'DeclinePrice': 0.00037848423, 'DeclineToSell': 0.00037848423, 'HaveDeinstalledEquipment': 0.00037848423, 'HaveEquipment': 0.00037848423, 'HaveInstalledEquipment': 0.00037848423, 'OfferPrice': 0.00037848423, 'WantToBuy': 0.00037848423, 'WantToSell': 0.00037848423}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"next week.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13d1917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OfferPrice': 0.8050674, 'DeclinePrice': 0.043331653, 'WantDeal': 0.026522988, 'Accept': 0.021000506, 'WantToBuy': 0.009999576, 'WantToSell': 0.009021949, 'AskIfSell': 0.0085871555, 'AskForPrice': 0.0067168144, 'AskForEquipmentInstallation': 0.006112825, 'Decline': 0.005915982, 'AskForInterest': 0.005772312, 'AskIfBuy': 0.005772312, 'AskIfHaveEquipment': 0.005772312, 'DeclineToBuy': 0.005772312, 'DeclineToSell': 0.005772312, 'DoNotHaveEquipment': 0.005772312, 'HaveDeinstalledEquipment': 0.005772312, 'HaveEquipment': 0.005772312, 'HaveInstalledEquipment': 0.005772312, 'None': 0.005772312}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"we can offer $ 70,000 for the picosun ald in an effort to try to come to an agreement this week .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72c774a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DeclinePrice': 0.458032, 'OfferPrice': 0.3456582, 'WantToBuy': 0.020721454, 'DeclineToBuy': 0.01794207, 'HaveDeinstalledEquipment': 0.012771096, 'Accept': 0.011869908, 'DoNotHaveEquipment': 0.01055394, 'AskForEquipmentInstallation': 0.00941933, 'AskForInterest': 0.00941933, 'AskForPrice': 0.00941933, 'AskIfBuy': 0.00941933, 'AskIfHaveEquipment': 0.00941933, 'AskIfSell': 0.00941933, 'Decline': 0.00941933, 'DeclineToSell': 0.00941933, 'HaveEquipment': 0.00941933, 'HaveInstalledEquipment': 0.00941933, 'None': 0.00941933, 'WantDeal': 0.00941933, 'WantToSell': 0.00941933}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"$ 19k / ea is much beyond my budget even it is new .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac4c6529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OfferPrice': 0.8750039, 'DeclinePrice': 0.03894349, 'Accept': 0.008771657, 'AskForPrice': 0.006042685, 'DoNotHaveEquipment': 0.0058640083, 'HaveInstalledEquipment': 0.0057974737, 'AskIfHaveEquipment': 0.0050947145, 'DeclineToBuy': 0.004916713, 'AskIfSell': 0.0043785004, 'HaveEquipment': 0.0041912934, 'WantToBuy': 0.0041264826, 'AskForEquipmentInstallation': 0.0040965592, 'AskForInterest': 0.0040965592, 'AskIfBuy': 0.0040965592, 'Decline': 0.0040965592, 'DeclineToSell': 0.0040965592, 'HaveDeinstalledEquipment': 0.0040965592, 'None': 0.0040965592, 'WantDeal': 0.0040965592, 'WantToSell': 0.0040965592}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"my customer budget for candella candela cs20r is 125k based on working condition mike .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92fa87ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HaveEquipment': 0.6787693, 'None': 0.06630386, 'WantToBuy': 0.055241153, 'HaveInstalledEquipment': 0.028903458, 'WantToSell': 0.017660655, 'DeclineToBuy': 0.015195864, 'AskIfHaveEquipment': 0.014255892, 'DoNotHaveEquipment': 0.013900739, 'Accept': 0.010701824, 'WantDeal': 0.0103576025, 'AskForEquipmentInstallation': 0.008870973, 'AskForInterest': 0.008870973, 'AskForPrice': 0.008870973, 'AskIfBuy': 0.008870973, 'AskIfSell': 0.008870973, 'Decline': 0.008870973, 'DeclinePrice': 0.008870973, 'DeclineToSell': 0.008870973, 'HaveDeinstalledEquipment': 0.008870973, 'OfferPrice': 0.008870973}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"we have a dual turn with gantry loader already .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c332e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'None': 0.95788217, 'WantDeal': 0.0064416113, 'Accept': 0.0055891047, 'HaveEquipment': 0.0026963954, 'AskForInterest': 0.0021464126, 'HaveInstalledEquipment': 0.0021373157, 'WantToBuy': 0.0019657295, 'Decline': 0.0017855184, 'AskForPrice': 0.0016936002, 'AskForEquipmentInstallation': 0.0016056527, 'AskIfBuy': 0.0016056527, 'AskIfHaveEquipment': 0.0016056527, 'AskIfSell': 0.0016056527, 'DeclinePrice': 0.0016056527, 'DeclineToBuy': 0.0016056527, 'DeclineToSell': 0.0016056527, 'DoNotHaveEquipment': 0.0016056527, 'HaveDeinstalledEquipment': 0.0016056527, 'OfferPrice': 0.0016056527, 'WantToSell': 0.0016056527}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"but it is still being used not heavily but still being used w / back side alignment .\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f914ccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DeclineToBuy': 0.39440435, 'WantToBuy': 0.09077857, 'DoNotHaveEquipment': 0.07007594, 'DeclineToSell': 0.052167118, 'Accept': 0.046616547, 'WantToSell': 0.04427364, 'AskIfSell': 0.04102678, 'DeclinePrice': 0.033389885, 'AskForEquipmentInstallation': 0.018938933, 'AskForInterest': 0.018938933, 'AskForPrice': 0.018938933, 'AskIfBuy': 0.018938933, 'AskIfHaveEquipment': 0.018938933, 'Decline': 0.018938933, 'HaveDeinstalledEquipment': 0.018938933, 'HaveEquipment': 0.018938933, 'HaveInstalledEquipment': 0.018938933, 'None': 0.018938933, 'OfferPrice': 0.018938933, 'WantDeal': 0.018938933}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"We do not have approval to purchase anything yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e399ca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AskIfBuy': 0.40539405, 'WantToBuy': 0.15079449, 'AskIfHaveEquipment': 0.056698907, 'OfferPrice': 0.048500527, 'DeclineToBuy': 0.033242956, 'DeclinePrice': 0.027137954, 'HaveInstalledEquipment': 0.022355612, 'AskIfSell': 0.021021193, 'DeclineToSell': 0.020554036, 'HaveEquipment': 0.020016804, 'AskForEquipmentInstallation': 0.01991136, 'HaveDeinstalledEquipment': 0.01963216, 'Accept': 0.019342504, 'AskForInterest': 0.019342504, 'AskForPrice': 0.019342504, 'Decline': 0.019342504, 'DoNotHaveEquipment': 0.019342504, 'None': 0.019342504, 'WantDeal': 0.019342504, 'WantToSell': 0.019342504}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"who needs this equipment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d310ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AskForPrice': 0.73943543, 'OfferPrice': 0.04992528, 'Accept': 0.030277442, 'DeclinePrice': 0.026345072, 'DoNotHaveEquipment': 0.017538743, 'None': 0.015950209, 'HaveEquipment': 0.013294258, 'AskIfHaveEquipment': 0.0106658945, 'Decline': 0.009230645, 'HaveInstalledEquipment': 0.009075862, 'AskIfSell': 0.0085241785, 'AskForEquipmentInstallation': 0.0077485545, 'AskForInterest': 0.0077485545, 'AskIfBuy': 0.0077485545, 'DeclineToBuy': 0.0077485545, 'DeclineToSell': 0.0077485545, 'HaveDeinstalledEquipment': 0.0077485545, 'WantDeal': 0.0077485545, 'WantToBuy': 0.0077485545, 'WantToSell': 0.0077485545}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"pls help me to find FEI FIB ,200,450\") ## not correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "995ce1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DeclineToSell': 0.57138395, 'WantToSell': 0.10745828, 'DeclinePrice': 0.038377095, 'DeclineToBuy': 0.037403964, 'WantToBuy': 0.03374374, 'DoNotHaveEquipment': 0.027715765, 'HaveDeinstalledEquipment': 0.02268651, 'AskIfSell': 0.019911686, 'Decline': 0.013121919, 'Accept': 0.011654278, 'AskForEquipmentInstallation': 0.011654278, 'AskForInterest': 0.011654278, 'AskForPrice': 0.011654278, 'AskIfBuy': 0.011654278, 'AskIfHaveEquipment': 0.011654278, 'HaveEquipment': 0.011654278, 'HaveInstalledEquipment': 0.011654278, 'None': 0.011654278, 'OfferPrice': 0.011654278, 'WantDeal': 0.011654278}\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, \"Sorry we are buying not selling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765834fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
